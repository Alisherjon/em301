# Парсинг данных в R

Нужные данные часто содержатся на сайтах в разной форме. Это только студенты по наивности думают, что `.csv` или `.dat` файлы как булки на деревьях растут. 


Загружаем две основных библиотеки для парсинга:
```{r}
library(XML) # parsing XML files
library(RCurl) # filling forms 
# on Ubuntu you need to install `libcurl4-gnutls-dev` before installing RCurl
```

## Популярные формы представления данных в Интернете

* JSON
* XML
* абы как внутри HTML

## JSON


## XML

### По жизни я везунчик

Если везёт, то данные из XML в data.frame можно переделать одной командой

### Найти нужные данные в XML

Есть два стратегии искать данные в XML файле. Одна удобна для небольших деревьев, другая требует больше усилий, но позволяет работать с огромнейшими XML файлами.

...


## HTML


### Парсинг готовых html-таблиц

В википедии есть данные по тому, сколько медалей получила каждая страна  в Олимпийских играх. Для начала нужно поглядеть на данные за [2010 год](http://en.wikipedia.org/wiki/2010_Winter_Olympics_medal_table). 


Мы их попытаемся вытащить автоматом. Потом, например, можно узнать как связано количество серебряных и золотых медалей. 

Находим все таблицы и смотрим, что там нашлось:
```{r}
url <- "http://en.wikipedia.org/wiki/2010_Winter_Olympics_medal_table"
tables <- readHTMLTable(url)
str(tables)
```

Судя по описанию, понимаем, что наша таблица --- третья из полученных:

```{r}
df <- tables[[3]]
str(df)
```

### Чистка таблиц из-за объединённых ячеек

Часто бывает, что в таблице были объединенные ячейки и тогда данные в некоторых строках оказываются смещены. У нас меньше 30 наблюдений и можно почистить руками, но мы потренируемся, чтобы быть готовыми к таблице с миллионом строк.

```{r}
df[5:9,]
```

Узнаем, какие строчки сдвинуты:
```{r}
to.correct <- is.na(df$Total)
to.correct
```

R пытается автоматом присвоить переменным правильный тип (целое число, дробное число, факторная переменная). И для избежания ошибок создаёт разные запреты: например, если у факторной переменной было заявлено два значения "да" и "нет", то присвоить ей что-то иное не получится. 

Поскольку у нас возникла путаница, то мы сначала переведем все переменные в текстовые, чтобы R не ругался на якобы ошибочные действия:

```{r}
df$Rank <- as.character(df$Rank)
df$Nation <- as.character(df$Nation)
df$Gold <- as.character(df$Gold)
df$Silver <- as.character(df$Silver)
df$Bronze <- as.character(df$Bronze)
df$Total <- as.character(df$Total)
```

Сдвигаем нужные строки:
```{r}
df[to.correct,2:6] <- df[to.correct,1:5]
```

Указываем правильные типы данных:
```{r}
df$Nation <- as.character(df$Nation)
df$Gold <- as.numeric(df$Gold)
df$Silver <- as.numeric(df$Silver)
df$Bronze <- as.numeric(df$Bronze)
df$Total <- as.numeric(df$Total)
```

Смотрим на почти идеальную таблицку. Останется только присвоить правильный ранг там, где сейчас в графе ранг стоит название страны:

```{r}
df[5:9,]
summary(df)
```

Кстати, Гугл-докс тоже умеет это делать! Создаёте пустую таблицу на [docs.google.com](docs.google.com). В верхней левой ячейке набираете:
```{r, eval=FALSE}
=ImportHtml("http://en.wikipedia.org/wiki/2010_Winter_Olympics_medal_table","table",3)
```
И наслаждаетесь тем же результатом!

### данные абы-как в HTML

...


### JavaScript внутри HTML

Тут начинается хардкор. Говорят, проще python + selenium


## Работа с текстовыми переменными

При копании в текстовых данных полезны бывают фукнции

* заменить
* разделить по слову
* проверить, входит ли слово в строку

## Конвертация текстовых данных в другие форматы

Текстовые данные могут быть:

* оставлены в текстовом формате, если речь идёт о названии региона
* отконвертированы в качественную переменную, если это ответы типа "да" или "нет"
* отконвертированы в количественную, если, скажем, это цена
* отконвертированы в дату и время


## Регулярные выражения

[О мощи регулярного шаманства](https://xkcd.com/208/)





## Отправить форму


## Работа с файлами

Порой мы насохраняли много однотипных файлов и нужно их объединить автоматически в один. 

Получаем список файлов  с расшерением `.csv` в текущей папке:
```{r}
file.list <- dir("*.csv")
print(file.list)
```

А дальше их можно читать в цикле:
```{r}

all.data <- NULL

for (f in file.list) {
  data <- read.csv(f) # читаем очередной файл
  cat(paste("Файл ",f,"содержит",nrow(data),"строк."))
  all.data <- rbind(all.data,data) # дописываем его в большую табличку
}
```

И на выходе мы получаем большой массив данных
```{r}
str(all.data)
```


## Готовые пирожки

Если источник данных очень популярный, то наверняка, его уже распарсили.

### TwitteR

### quantmod


## Где порыться?

* Можно парсить данные с помощью другого языка программирования, и только потом статистическую обработку делать в R. Например, подойдёт Питон с библиотеками `beautiful soup` или `lxml`.

* Можно поискать готовые программы для парсинга. Их много платных. Есть бесплатные.  Зачастую (личное мнение) чтобы разобраться с программой уйдёт времени почти столько же, сколько на программирование, а пользы явно меньше. Всё-таки при парсинге приходится решать кучу мелких технических вопросов.



Хвосты:



```{r}
url <- "http://www.databasesports.com/olympics/sport/sportevent.htm?sp=ATH&enum=120"
data <- readHTMLTable(url)
str(data)

# get the right table
df.mock <- data[[3]]
df.mock

# clean table
str(df.mock)
df.mock$Year <- as.numeric(as.character(df.mock$Year))
df.mock$Result <- as.numeric(as.character(df.mock$Result))

df <- df.mock[,-2]

# check
str(df)
head(df)
tail(df)
```


```{r}
url <- "http://sophist.hse.ru/exes/tables/IP_EA_Q.htm"
data <- readHTMLTable(url)
str(data)

df <- data[[1]]

head(df)
tail(df)

df.clean <- df[2:(nrow(df)-4),]
df.clean

df.clean$IP_EA_Q <- gsub(",",".",df.clean$IP_EA_Q)
df.clean$IP_EA_Q_SA <- gsub(",",".",df.clean$IP_EA_Q_SA)
```




