\documentclass[pdftex,12pt,a4paper]{article}

\input{/home/boris/science/tex_general/title_bor_utf8}

% чисто эконометрические сокращения:
\def \hb{\hat{\beta}}
\def \hy{\hat{y}}
\def \hY{\hat{Y}}
\def \he{\hat{\varepsilon}}
\def \v1{\vec{1}}
\def \e{\varepsilon}
\def \hVar{\widehat{\Var}}
\def \hCorr{\widehat{\Corr}}




% временное решение
%\newcommand{\solution}[1]{ {\tiny #1} }
\newcommand{\solution}[1]{}

\newcommand{\problem}[1]{#1}

\title{Задачник по эконометрике-1 \\ {\small (с шахматами и поэтэссами)}}
\author{Дмитрий Борзых, Борис Демешев}
\date{\today}

\makeindex % команда для создания предметного указателя
\bibliographystyle{plain} % стиль оформления ссылок


\begin{document}

\maketitle % печатаем заголовок


\parindent=0 pt % отступ равен 0

\section{Неклассифицировано}

\begin{enumerate}
\item Регрессионная модель  задана в матричном виде при помощи уравнения $y=X\beta+\varepsilon$, где $\beta=(\beta_1,\beta_2,\beta_3)'$.
Известно, что $\E(\varepsilon)=0$  и  $\Var(\varepsilon)=\sigma^2\cdot I$.
Известно также, что 

$y=\left(
\begin{array}{c} 
1\\ 
2\\ 
3\\ 
4\\ 
5
\end{array}\right)$, 
$X=\left(\begin{array}{ccc}
1 & 0 & 0 \\
1 & 0 & 0 \\
1 & 0 & 0 \\
1 & 1 & 0 \\
1 & 1 & 1 
\end{array}\right)$.


Для удобства расчетов приведены матрицы 


$X'X=\left(
\begin{array}{ccc} 
5 & 2 & 1\\ 
2 & 2 & 1\\ 
1 & 1 & 1 
\end{array}\right)$ и $(X'X)^{-1}=\frac{1}{3}\left(
\begin{array}{ccc} 
1 & -1 & 0 \\
-1 & 4 & -3 \\
0 & -3 & 6
\end{array}\right)$.

\begin{enumerate}
\item Укажите число наблюдений.
\item Укажите число регрессоров с учетом свободного члена.
\item Рассчитайте $TSS=\sum (y_i-\bar{y})^2$, $RSS=\sum (y_i-\hat{y}_i)^2$ и $ESS=\sum (\hat{y}_i-\bar{y})^2$.
\item Рассчитайте при помощи метода наименьших квадратов $\hb$, оценку для вектора неизвестных коэффициентов.
\item Чему равен $\he_5$, МНК-остаток регрессии, соответствующий 5-ому наблюдению?
\item Чему равен $R^2$  в модели? Прокомментируйте полученное значение с точки зрения качества оцененного уравнения регрессии.
\item Используя приведенные выше данные, рассчитайте несмещенную оценку для неизвестного параметра $\sigma^2$ регрессионной модели.
\item Рассчитайте $\widehat{\Var}(\hb)$, оценку для ковариационной матрицы вектора МНК-коэффициентов $\hb$.  
\item Найдите $\widehat{\Var}(\hb_1)$, несмещенную оценку дисперсии МНК-коэффициента $\hb_1$.
\item Найдите $\widehat{\Var}(\hb_2)$, несмещенную оценку дисперсии МНК-коэффициента $\hb_2$.
\item Найдите $\widehat{\Cov}(\hb_1,\hb_2)$, несмещенную оценку ковариации МНК-коэффициентов $\hb_1$ и $\hb_2$.
\item Найдите $\widehat{\Var}(\hb_1+\hb_2)$, $\widehat{\Var}(\hb_1-\hb_2)$, $\widehat{\Var}(\hb_1+\hb_2+\hb_3)$, $\widehat{\Var}(\hb_1+\hb_2-2\hb_3)$
\item Найдите $\hCorr(\hb_1,\hb_2)$, оценку коэффициента корреляции МНК-коэффициентов $\hb_1$ и $\hb_2$.
\item Найдите $s_{\hb_1}$, стандартную ошибку МНК-коэффициента $\hb_1$.
\item Рассчитайте выборочную ковариацию $y$ и $\hy$.
\item Найдите выборочную дисперсию $y$, выборочную дисперсию $\hy$.
\end{enumerate}

\item Априори известно, что парная регрессия должна проходить через точку $(x_{0},y_{0})$.
\begin{enumerate}
\item  Выведите формулы МНК оценок;
\item В предположениях теоремы Гаусса-Маркова найдите дисперсии и средние оценок 
\end{enumerate}

\solution{Вроде бы равносильно переносу начала координат и применению результата для регрессии без свободного члена. Должна остаться несмещенность. }




\item \problem{ Слитки-вариант. Перед нами два золотых слитка и весы, производящие взвешивания с ошибками. Взвесив первый слиток, мы получили результат $300$ грамм, взвесив второй слиток --- $200$ грамм, взвесив оба слитка --- $400$ грамм. Предположим, что ошибки взвешивания --- независимые одинаково распределенные случайные величины с нулевым средним. 
\begin{enumerate}
\item Найдите несмещеную оценку веса первого шара, обладающую наименьшей дисперсией.
\item Как можно проинтерпретировать нулевое математическое ожидание ошибки взвешивания? 
\end{enumerate} }
\solution{ Как отсутствие систематической ошибки.} 

\item Вася считает, что $\sCov(y,\hy)=\frac{\sum (y_i-\bar{y})(\hy_i-\bar{y})}{n-1}$ это неплохая оценка для $\Cov(y_i,\hy_i)$. Прав ли он?
\solution{Не прав. Ковариация $\Cov(y_i,\hy_i)$ зависит от $i$, это не одно неизвестное число, для которого можно предложить одну оценку.}


\item Сгенерировать набор данных, обладающий следующим свойством. Если попытаться сразу выкинуть регрессоры $x$ и $z$, то гипотеза о их совместной незначимости отвергается. Если вместо этого попытаться выкинуть отдельно $x$, или отдельно $z$, то гипотеза о незначимости не отвергается.
\solution{Сгенерировать сильно коррелированные $x$ и $z$}


\item Сгенерировать набор данных, обладающий следующим свойством. Если попытаться сразу выкинуть регрессоры $x$ и $z$, то гипотеза о их совместной незначимости отвергается. Если вместо сначала выкинуть отдельно $x$, то гипотеза о незначимости не отвергается. Если затем выкинуть $z$, то гипотезы о незначимости тоже не отвергается.
\solution{??}

\item К эконометристу Вовочке в распоряжение попали данные с результатами контрольной работы студентов по эконометрике. В данных есть результаты по каждой задаче, переменные $p_1$, $p_2$, $p_3$, $p_4$ и $p_5$, и суммарный результат за контрольную, переменная $kr$. Чему будут равны оценки коэффициентов, их стандартные ошибки, t-статистики, P-значения, $R^2$, $RSS$, если
\begin{enumerate}
\item Вовочка построит регрессию $kr$ на константу, $p_1$, $p_2$, $p_3$, $p_4$ и $p_5$
\item Вовочка построит регрессию $kr$ на $p_1$, $p_2$, $p_3$, $p_4$ и $p_5$ без константы
\end{enumerate}
\solution{}


\item Как построить доверительный интервал для вершины параболы? ...
\solution{bootstrap, дельта-метод}
% Спросить Лену

\item Про $R^2_{adj}$
\begin{enumerate}
\item Может ли в модели с константой $R^2_{adj}$ быть отрицательным?
\item Что больше, $R^2$ или $R^2_{adj}$ в модели с константой?
\item Вася оценил модель $A$, а затем выкинул из нее регрессор $z$ и оценил получившуюся модель $B$. В моделях $A$ и $B$ оказались равные $R^2_{adj}$. Чему равна $t$-статистика коэффициента при $z$ в модели $A$?
\item Есть две модели с одной и той же зависимой переменной, но с разными объясняющими переменными, модель $A$ и модель $B$. В модели $A$ коэффициент $R^2_{adj}$ больше, чем в модели $B$. В какой из моделей больше коэффициент $\hat{\sigma^2}$? 
\end{enumerate}
\solution{да, $R^2$, $t=1$, $B$ }


\item В классической линейной регрессионной модели $y_i=\beta_1+\beta_2 x_i+\e_i$, дисперсия зависимой переменной не зависит от номера наблюдения, $\Var(y_i)=\sigma^2$. Почему для оценки $\sigma^2$ вместо известной из курса математической статистики формулы $\sum (y_i-\bar{y})^2/(n-1)$ используют $\sum \he_i^2/(n-2)$?
\solution{формула $\sum (y_i-\bar{y})^2/(n-1)$ неприменима так как $\E(y_i)$ не является константой }


\item Оценка регрессии имеет вид $\hy_i=3-2x_i$. Выборочная дисперсия $x$ равна $9$, выборочная дисперсия $y$ равна $40$. Найдите $R^2$ и выборочные корреляции $\sCorr(x,y)$, $\sCorr(y,\hy)$.
\solution{$R^2$ --- это отношение выборочных дисперсий $\hy$ и $y$. } 

\item У эконометриста Вовочки есть переменная $1_f$, которая равна 1, если $i$-ый человек в выборке --- женщина, и 0, если мужчина. Есть переменная $1_m$, которая равна 1, если $i$-ый человек в выборке --- мужчина, и 0, если женщина. Какие $\hy$ получатся, если Вовочка попытается построить регрессии:
\begin{enumerate}
\item $y$ на константу и $1_f$
\item $y$ на константу и $1_m$
\item $y$ на $1_f$ и $1_m$ без константы
\item $y$ на константу, $1_f$ и $1_m$
\end{enumerate}


\item У эконометриста Вовочки есть три переменных: $r_i$ --- доход $i$-го человека в выборке, $m_i$ --- пол (1 --- мальчик, 0 --- девочка) и $f_i$ --- пол (1 --- девочка, 0 --- мальчик). Вовочка оценил две модели
\begin{enumerate}
\item[Модель A] $m_i=\beta_1+\beta_2 r_i+\ve_i$
\item[Модель B] $f_i=\gamma_1+\gamma_2 r_i+u_i$
\end{enumerate}
\begin{enumerate}
\item Как связаны между собой оценки $\hb_1$ и $\hat{\gamma}_1$?
\item Как связаны между собой оценки $\hb_2$ и $\hat{\gamma}_2$? 
\end{enumerate}
\solution{ Оценки МНК линейны по объясняемой переменной. Если сложить объясняемые переменные в этих двух моделях, то получится вектор из единичек. Если строить регрессию вектора из единичек на константу и $r$, то получатся оценки коэффициентов 1 и 0. Значит, $\hb_1+\hat{\gamma}_1=1$, $\hb_2+\hat{\gamma}_2=0$ }


\item Эконометрист Вовочка оценил линейную регрессионную модель, где $y$ измерялся в тугриках. Затем он оценил ту же модель, но измерял $y$ в мунгу (1 тугрик = 100 мунгу). Как изменятся оценки коэффициентов?
\solution{Увеличатся в 100 раз}

\item Возможно ли, что при оценке парной регрессии $y=\beta_1+\beta_2 x+\e$ оказывается, что $\hb_2>0$, а при оценке регрессии без константы, $y=\gamma x+\e$, оказывается, что $\hat{\gamma}<0$?
\solution{да}


\item Эконометрист Вовочка оценил регрессию $y$ только на константу. Какой коэффициент $R^2$ он получит?
\solution{$R^2=0$}



\end{enumerate}

\section{МНК без матриц и вероятностей}

\begin{enumerate}
\item \problem{Даны $n$ пар чисел: $(x_1, y_1)$, \ldots, $(x_n,y_n)$. Мы прогнозируем $y_i$ по формуле $\hy_i=\hb x_i$. Найдите $\hb$ методом наименьших квадратов. }
\solution{$\hb=\sum x_i y_i/\sum x_i^2$}

\item \problem{Даны $n$ чисел: $y_1$, \ldots, $y_n$. Мы прогнозируем $y_i$ по формуле $\hy_i=\hb$. Найдите $\hb$ методом наименьших квадратов. }
\solution{$\hb=\bar{y}$}

\item \problem{Даны $n$ пар чисел: $(x_1, y_1)$, \ldots, $(x_n,y_n)$. Мы прогнозируем $y_i$ по формуле $\hy_i=\hb_1+\hb_2 x_i$. Найдите $\hb_1$ и $\hb_2$ методом наименьших квадратов. }
\solution{$\hb_2=\sum (x_i-\bar{x})(y_i-\bar{y})/\sum(x_i-\bar{x})^2$, $\hb_1=\bar{y}-\hb_2\bar{x}$}

\item \problem{Даны $n$ пар чисел: $(x_1, y_1)$, \ldots, $(x_n,y_n)$. Мы прогнозируем $y_i$ по формуле $\hy_i=1+\hb x_i$. Найдите $\hb$ методом наименьших квадратов. }
\solution{$\hb=\sum x_i (y_i-1)/\sum x_i^2$}

\item \problem{ Перед нами два золотых слитка и весы, производящие взвешивания с ошибками. Взвесив первый слиток, мы получили результат $300$ грамм, взвесив второй слиток --- $200$ грамм, взвесив оба слитка --- $400$ грамм. Оцените вес каждого слитка методом наименьших квадратов.}
\solution{ $(300-\hb_1)^2+(200-\hb_2)^2+(400-\hb_1-\hb_2)^2\to\min$ }


\item Аня и Настя утверждают, что лектор опоздал на 10 минут. Таня считает, что лектор опоздал на 3 минуты. С помощью мнк оцените на сколько опоздал лектор. 
\solution{ $2\cdot (10-\hb)^2+(3-\hb)^2\to\min$ }

\item Регрессия на дамми-переменную...



\item Функция $f(x)$ дифференциируема на отрезке $[0;1]$. Найдите аналог МНК-оценок для регрессии без свободного члена в непрерывном случае. Более подробно: найдите минимум по $\hb$ для функции
\begin{equation}
Q(\hb)= \int_0^1 (f(x)-\hb x)^2\,dx
\end{equation}
\solution{}

\item Есть двести наблюдений. Вовочка оценил модель $\hy=\hb_1+\hb_2 x$ по первой сотне наблюдений. Петечка оценил модель $\hy=\hat{\gamma}_1+\hat{\gamma}_2 x$ по второй сотне наблюдений. Машенька оценила модель $\hy=\hat{m}_1+\hat{m}_2 x$ по всем наблюдениям.
\begin{enumerate}
\item Возможно ли, что $\hb_2>0$, $\hat{\gamma}_2>0$, но $\hat{m}_2<0$?
\item Возможно ли, что $\hb_1>0$, $\hat{\gamma}_1>0$, но $\hat{m}_1<0$?
\item Возможно ли одновременное выполнение всех упомянутых условий?
\end{enumerate}
\solution{да, возможно. Два вытянутых облачка точек. Первое облачко даёт первую регрессию, второе --- вторую. Прямая, соединяющая центры облачков, --- общую.}



\item Вася оценил модель $y=\beta_1+\beta_2 d+\beta_3 x+\varepsilon$. Дамми-переменная $d$ обозначает пол, 1 для мужчин и 0 для женщин. Оказалось, что $\hat{\beta}_2>0$. Означает ли это, что для мужчин $\bar{y}$ больше, чем $\bar{y}$ для женщин?
\solution{Нет. Коэффициенты можно интепретировать только <<при прочих равных>>, т.е. при равных $x$. Из-за разных $x$ может оказаться, что у мужчин $\bar{y}$ меньше, чем $\bar{y}$ для женщин.}


\item Какие из указанные моделей можно представить в линейном виде?
\begin{enumerate}
\item $y_i=\beta_1+\frac{\beta_2}{x_i}+\e_i$
\item $y_i=\exp(\beta_1+\beta_2 x_i+\e_i)$
\item $y_i=1+\frac{1}{\exp(\beta_1+\beta_2 x_i+\e_i)}$
\item $y_i=\frac{1}{1+\exp(\beta_1+\beta_2 x_i+\e_i)}$
\item $y_i=x_i^{\beta_2}e^{\beta_1+\e_i}$
\end{enumerate}
\solution{}

\end{enumerate}

\section{Инструментальные переменные}


Экзогенность, $\E(\e\mid x)=0$


Предопределённость, $\E(\e_t\mid x_t)=0$ для всех $t$

\begin{enumerate}
\item Табличка 2 на 2. Найдите $\E(\varepsilon)$, $\E(\varepsilon|x)$, $\Cov(\varepsilon,x)$.
\solution{}

\item Приведите примеры дискретных случайных величин $\e$ и $x$, таких, что
\begin{enumerate}
\item $\E(\e)=0$, $\E(\e\mid x)=0$, но величины зависимы. Чему в этом случае равно $\Cov(\e,x)$?
\item $\E(\e)=0$, $\Cov(\e,x)=0$, но $\E(\e\mid x)\neq 0$. Зависимы ли эти случайные величины? 
\end{enumerate}
\solution{}

\item Все предпосылки классической линейной модели выполнены, $y=\beta_1+\beta_2 x+\varepsilon$. Рассмотрим альтернативную оценку коэффициента $\beta_2$,
\begin{equation}
\hb_{2,IV}=\frac{\sum z_i(y_i-\bar{y})}{\sum z_i(x_i-\bar{x})}
\end{equation}
\begin{enumerate}
\item Является ли оценка несмещенной?
\item Любые ли $z_i$ можно брать?
\item Найдите $\Var(\hb_{2,IV})$
\end{enumerate}
\solution{Да, является. Любые, кроме констант. $\Var(\hb_{2,IV})=\sigma^2 \sum (z_i-\bar{z})^2/ \left(\sum (z_i-\bar{z})x_i \right)^2 $.}

\item 
\end{enumerate}


\section{Проекция, Картинка}
\begin{enumerate}
\item Найдите на Картинке четыре прямоугольных треугольника. Сформулируйте четыре теоремы Пифагора.
\solution{$\sum y_i^2=\sum \hy_i^2+\sum \he_i^2$, $TSS=ESS+RSS$, }

\item Покажите на Картинке TSS, ESS, RSS, $R^2$, $\sCov(\hy,y)$
\solution{}


\item Предложите аналог $R^2$ для случая, когда константа среди регрессоров отсутствует. Аналог должен быть всегда в диапазоне $[0;1]$, совпадать с обычным $R^2$, когда среди регрессоров есть константа, равняться единице в случае нулевого $\he$.
\solution{Спроецируем единичный столбец на <<плоскость>>, обозначим его $1'$. Делаем проекцию $y$ на <<плоскость>> и на $1'$. Далее аналогично. }

\item Вася оценил регрессию $y$ на константу, $x$ и $z$. А затем, делать ему нечего, регрессию $y$ на константу и полученный $\hy$. Какие оценки коэффициентов у него получатся? Чему будет равна оценка дисперсии коэффицента при $\hy$? Почему оценка коэффициента неслучайна, а оценка её дисперсии положительна?
\solution{Проекция $y$ на $\hy$ это $\hy$, поэтому оценки коэффициентов будут 0 и 1. Оценка дисперсии $\frac{RSS}{(n-2)ESS}$. Нарушены предпосылки теоремы Гаусса-Маркова, например, ошибки новой модели в сумме дают 0, значит коррелированы. } 


\item При каких условиях $TSS=ESS+RSS$?
\solution{Либо в регрессию включена константа, либо единичный столбец (тут была опечатка, столбей) можно получить как линейную комбинацию регрессоров, например, включены дамми-переменные для каждого возможного значения качественной переменной.}


\end{enumerate}

\section{МЕГАМАТРИЦА}

\begin{enumerate}
\item В рамках классической линейной модели найдите все математические ожидания и все ковариационные матрицы всех пар случайных векторов: $\ve$, $y$, $\hy$, $\he$, $\hb$. Т.е. найдите $\E(\e)$, $\E(y)$, \ldots и $\Cov(\e,y)$, $\Cov(\e,\hy)$, \ldots
\solution{$\Var(\hb)=\sigma^2 (X'X)^{-1}$}

\item Найдите $\E(\sum (\e_i-\bar{\e})^2 )$, $\E(RSS)$
\solution{ $(n-1)\sigma^2$, $(n-k)\sigma^2$}

\item $\E(TSS)$, $\E(ESS)$ --- громоздкие 
\solution{ $\E(TSS)=(n-1)\sigma^2+\beta'X'(I-\pi)X\beta$}

\item Вася строит регрессию $y$ на некий набор объясняющих переменных и константу. А на самом деле $y_i=\beta_1+\e_i$. Чему равно $\E(TSS)$, $\E(RSS)$, $\E(ESS)$ в этом случае?
\solution{ $(n-1)\sigma^2$, $(n-k)\sigma^2$, $(k-1)\sigma^2$}

\end{enumerate}



\section{Голая линейная алгебра}

Здесь будет собран минимум задач по линейной алгебре.

\begin{enumerate}
\item \problem{Приведите пример таких $A$ и $B$, что $\det(AB)\neq \det(BA)$.}
\solution{Например, $A=(1,2,3)$, $B=(1,0,1)'$}

\item Для матриц-проекторов $\pi=\v1(\v1'\v1)^{-1}\v1'$ и $P=X(X'X)^{-1}X'$ найдите $\tr(\pi)$, $\tr(P)$, $\tr(I-\pi)$, $\tr(I-P)$.
\solution{$\tr(I)=n$, $\tr(\pi)=1$, $\tr(P)=k$ }

\item Выпишите в явном виде матрицы $X'X$, $(X'X)^{-1}$ и $X'y$, если

$y=\left(
\begin{array}{c}
y_1 \\
y_2 \\
\vdots \\
y_n 
\end{array}\right)$ и
$X=\left(
\begin{array}{cc}
1 & x_1 \\
1 & x_2 \\
\vdots & \vdots \\
1 & x_n 
\end{array}\right)$ 
\solution{ }


\item Выпишите в явном виде матрицы $\pi$, $\pi y$, $\pi \e$, $I-\pi$, если $\pi=\v1(\v1'\v1)^{-1}\v1'$.
 
\end{enumerate}


\section{Компьютерные упражнения}

Все наборы данных доступны по ссылке \url{https://github.com/bdemeshev/em301/wiki/Datasets}.


\begin{enumerate}


\item Скачайте результаты двух контрольных работ по теории вероятностей, \url{} с описанием данных, \url{}. Наша задача попытаться предсказать результат второй контрольной работы зная позадачный результат первой контрольной, пол и группу студента. 
\begin{enumerate}
\item Какая задача из первой контрольной работы наиболее существенно влияет на результат второй контрольной?
\item Влияет ли пол на результат второй контрольной?
\item Влияет ли редкость имени на результат второй контрольной?
\item Что можно сказать про влияние группы, в которой учится студент?
\end{enumerate}
\solution{}

\item Задача Макар-Лиманова. У торговца 55 пустых стаканчиков, разложенных в несколько стопок. Пока нет покупателей он развлекается: берет верхний стаканчик из каждой стопки и формирует из них новую стопку. Потом снова берет верхний стаканчик из каждой стопки и формирует из них новую стопку и т.д.
\begin{enumerate}
\item Напишите функцию `makar\_step`. На вход функции подаётся вектор количества стаканчиков в каждой стопке до перекладывания. На выходе функция возвращает количества стаканчиков в каждой стопке после одного перекладывания.
\item Изначально стаканчики были разложены в две стопки, из 25 и 30 стаканчиков. Как разложатся стаканчики если покупателей не будет достаточно долго?
\end{enumerate}
\solution{}

\item Напишите функцию, которая бы оценивала регрессию методом наименьших квадратов. На вход функции должны подаваться вектор зависимых переменных $y$ и матрица регрессоров $X$. На выходе функция должна выдавать список из $\hb$, $\hVar(\hb)$, $\hy$, $\he$, $ESS$, $RSS$ и $TSS$. По возможности функция должна проверять корректность аргументов, например, что в $y$ и $X$ одинаковое число наблюдений и т.д.
\solution{}

\item Сгенерируйте вектор $y$ из 300 независимых нормальных $N(10,1)$ случайных величин. Сгенерируйте 40 <<объясняющих>> переменных, по 300 наблюдений в каждой, каждое наблюдение --- независимая нормальная $N(5,1)$ случайная величина. Постройте регрессию $y$ на все 40 регрессоров и константу. 
\begin{enumerate}
\item Сколько регрессоров оказалось значимо на 5\% уровне?
\item Сколько регрессоров в среднем значимо на 5\% уровне?
\item Эконометрист Вовочка всегда использует следующий подход: строит регрессию зависимой переменной на все имеющиеся регрессоры, а затем выкидывает из модели те регрессоры, которые оказались незначимы. Прокомментируйте Вовочкин эконометрический подход.
\end{enumerate}
\solution{}




\end{enumerate}


\section{Вопросы теоретического характера}

\begin{enumerate}
\item Что означают слова автокорреляция, гетероскедастичность, гомоскедастичность?
\item Напишите формулу для оценок коэффициентов в парной регрессии без матриц
\item Напишите формулу для оценок коэффициентов в множественной регрессии 
\item Аналогично для дисперсий

\end{enumerate}



\end{document}