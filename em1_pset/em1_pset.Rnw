\documentclass[pdftex,12pt,a4paper]{article}

\input{/home/boris/science/tex_general/title_bor_utf8_knitr}

\input{../emetrix_preamble}
% чисто эконометрические сокращения:


% временное решение
\newcommand{\solution}[1]{#1}

%\newcommand{\solution}[1]{ {\tiny #1} }
%\newcommand{\solution}[1]{}

\newcommand{\problem}[1]{#1}

\title{Задачник по эконометрике-1 \\ {\small (с шахматами и поэтэссами)}}
\author{Дмитрий Борзых, Борис Демешев}
\date{\today}

\makeindex % команда для создания предметного указателя
\bibliographystyle{plain} % стиль оформления ссылок


\begin{document}

\maketitle % печатаем заголовок
\tableofcontents

\parindent=0 pt % отступ равен 0



<<"setup", echo=TRUE, include=FALSE,tidy=FALSE>>=
library(knitr)
opts_chunk$set(cache=TRUE,
               dev="png",dpi=300,
               warning=FALSE,
               tidy=FALSE, 
               echo=TRUE,
               out.height="7cm",out.width="7cm") # кэшируем все куски по умолчанию

library(ggplot2)
library(Hmisc)
library(lmtest)
library(apsrtable)
library(xtable)

theme_set(theme_bw())
@

\listoftodos



\section{Проверка гипотез строго по уставу!}

\begin{enumerate}
\item Условия применимости теста
\item Формулировка $H_0$, $H_a$ и уровня значимости $\alpha$
\item Формула расчета и наблюдаемое значения статистики, $S_{obs}$
\item Закон распределения $S_{obs}$ при верной $H_0$
\item Область в которой $H_0$ не отвергается
\item Точное P-значение
\item Вывод
\end{enumerate}

В качестве вывода допускается только одна из двух фраз:
\begin{itemize}
\item Гипотеза $H_0$ отвергается
\item Гипотеза $H_0$ не отвергается
\end{itemize}

Остальные фразы считаются неуставными


\section{МНК без матриц и вероятностей}

\begin{enumerate}
\item \problem{Даны $n$ пар чисел: $(x_1, y_1)$, \ldots, $(x_n,y_n)$. Мы прогнозируем $y_i$ по формуле $\hy_i=\hb x_i$. Найдите $\hb$ методом наименьших квадратов. }
\solution{$\hb=\sum x_i y_i/\sum x_i^2$}

\item \problem{Даны $n$ чисел: $y_1$, \ldots, $y_n$. Мы прогнозируем $y_i$ по формуле $\hy_i=\hb$. Найдите $\hb$ методом наименьших квадратов. }
\solution{$\hb=\bar{y}$}

\item \problem{Даны $n$ пар чисел: $(x_1, y_1)$, \ldots, $(x_n,y_n)$. Мы прогнозируем $y_i$ по формуле $\hy_i=\hb_1+\hb_2 x_i$. Найдите $\hb_1$ и $\hb_2$ методом наименьших квадратов. }
\solution{$\hb_2=\sum (x_i-\bar{x})(y_i-\bar{y})/\sum(x_i-\bar{x})^2$, $\hb_1=\bar{y}-\hb_2\bar{x}$}

\item \problem{Даны $n$ пар чисел: $(x_1, y_1)$, \ldots, $(x_n,y_n)$. Мы прогнозируем $y_i$ по формуле $\hy_i=1+\hb x_i$. Найдите $\hb$ методом наименьших квадратов. }
\solution{$\hb=\sum x_i (y_i-1)/\sum x_i^2$}

\item \problem{ Перед нами два золотых слитка и весы, производящие взвешивания с ошибками. Взвесив первый слиток, мы получили результат $300$ грамм, взвесив второй слиток --- $200$ грамм, взвесив оба слитка --- $400$ грамм. Оцените вес каждого слитка методом наименьших квадратов.}
\solution{ $(300-\hb_1)^2+(200-\hb_2)^2+(400-\hb_1-\hb_2)^2\to\min$ }


\item Аня и Настя утверждают, что лектор опоздал на 10 минут. Таня считает, что лектор опоздал на 3 минуты. С помощью мнк оцените на сколько опоздал лектор. 
\solution{ $2\cdot (10-\hb)^2+(3-\hb)^2\to\min$ }

\item Регрессия на дамми-переменную...



\item Функция $f(x)$ дифференциируема на отрезке $[0;1]$. Найдите аналог МНК-оценок для регрессии без свободного члена в непрерывном случае. Более подробно: найдите минимум по $\hb$ для функции
\begin{equation}
Q(\hb)= \int_0^1 (f(x)-\hb x)^2\,dx
\end{equation}
\solution{}

\item Есть двести наблюдений. Вовочка оценил модель $\hy=\hb_1+\hb_2 x$ по первой сотне наблюдений. Петечка оценил модель $\hy=\hat{\gamma}_1+\hat{\gamma}_2 x$ по второй сотне наблюдений. Машенька оценила модель $\hy=\hat{m}_1+\hat{m}_2 x$ по всем наблюдениям.
\begin{enumerate}
\item Возможно ли, что $\hb_2>0$, $\hat{\gamma}_2>0$, но $\hat{m}_2<0$?
\item Возможно ли, что $\hb_1>0$, $\hat{\gamma}_1>0$, но $\hat{m}_1<0$?
\item Возможно ли одновременное выполнение всех упомянутых условий?
\end{enumerate}
\solution{да, возможно. Два вытянутых облачка точек. Первое облачко даёт первую регрессию, второе --- вторую. Прямая, соединяющая центры облачков, --- общую.}



\item Вася оценил модель $y=\beta_1+\beta_2 d+\beta_3 x+\varepsilon$. Дамми-переменная $d$ обозначает пол, 1 для мужчин и 0 для женщин. Оказалось, что $\hat{\beta}_2>0$. Означает ли это, что для мужчин $\bar{y}$ больше, чем $\bar{y}$ для женщин?
\solution{Нет. Коэффициенты можно интерпретировать только <<при прочих равных>>, т.е. при равных $x$. Из-за разных $x$ может оказаться, что у мужчин $\bar{y}$ меньше, чем $\bar{y}$ для женщин.}


\item Какие из указанные моделей можно представить в линейном виде?
\begin{enumerate}
\item $y_i=\beta_1+\frac{\beta_2}{x_i}+\e_i$
\item $y_i=\exp(\beta_1+\beta_2 x_i+\e_i)$
\item $y_i=1+\frac{1}{\exp(\beta_1+\beta_2 x_i+\e_i)}$
\item $y_i=\frac{1}{1+\exp(\beta_1+\beta_2 x_i+\e_i)}$
\item $y_i=x_i^{\beta_2}e^{\beta_1+\e_i}$
\end{enumerate}
\solution{}


\item У эконометриста Вовочки есть переменная $1_f$, которая равна 1, если $i$-ый человек в выборке --- женщина, и 0, если мужчина. Есть переменная $1_m$, которая равна 1, если $i$-ый человек в выборке --- мужчина, и 0, если женщина. Какие $\hy$ получатся, если Вовочка попытается построить регрессии:
\begin{enumerate}
\item $y$ на константу и $1_f$
\item $y$ на константу и $1_m$
\item $y$ на $1_f$ и $1_m$ без константы
\item $y$ на константу, $1_f$ и $1_m$
\end{enumerate}


\item У эконометриста Вовочки есть три переменных: $r_i$ --- доход $i$-го человека в выборке, $m_i$ --- пол (1 --- мальчик, 0 --- девочка) и $f_i$ --- пол (1 --- девочка, 0 --- мальчик). Вовочка оценил две модели
\begin{enumerate}
\item[Модель A] $m_i=\beta_1+\beta_2 r_i+\ve_i$
\item[Модель B] $f_i=\gamma_1+\gamma_2 r_i+u_i$
\end{enumerate}
\begin{enumerate}
\item Как связаны между собой оценки $\hb_1$ и $\hat{\gamma}_1$?
\item Как связаны между собой оценки $\hb_2$ и $\hat{\gamma}_2$? 
\end{enumerate}
\solution{ Оценки МНК линейны по объясняемой переменной. Если сложить объясняемые переменные в этих двух моделях, то получится вектор из единичек. Если строить регрессию вектора из единичек на константу и $r$, то получатся оценки коэффициентов 1 и 0. Значит, $\hb_1+\hat{\gamma}_1=1$, $\hb_2+\hat{\gamma}_2=0$ }


\item Эконометрист Вовочка оценил линейную регрессионную модель, где $y$ измерялся в тугриках. Затем он оценил ту же модель, но измерял $y$ в мунгу (1 тугрик = 100 мунгу). Как изменятся оценки коэффициентов?
\solution{Увеличатся в 100 раз}

\item Возможно ли, что при оценке парной регрессии $y=\beta_1+\beta_2 x+\e$ оказывается, что $\hb_2>0$, а при оценке регрессии без константы, $y=\gamma x+\e$, оказывается, что $\hat{\gamma}<0$?
\solution{да}


\item Эконометрист Вовочка оценил регрессию $y$ только на константу. Какой коэффициент $R^2$ он получит?
\solution{$R^2=0$}


\item Эконометрист Вовочка оценил методом наименьших квадратов модель 1, $y=\b_1+\b_2 x+\b_3 z+\e$, а затем модель 2, $y=\b_1+\b_2 x+\b_3 z+\b_4 w+\e$. Сравните полученные $ESS$, $RSS$, $TSS$ и $R^2$.
\solution{ $TSS_1=TSS_2$, $R_2^2\geq R_2^1$, $ESS_2\geq ESS_1$, $RSS_2\leq RSS_1$}



\item (?) Создайте набор данных с тремя переменными $y$, $x$ и $z$ со следующими свойствами. При оценке модели $\hy=\hb_1+\hb_2 x$ получается $\hb_2>0$. При оценке модели $\hy=\hat{\gamma}_1+ \hat{\gamma}_2 x+\hat{\gamma}_3 z$ получается $\hat{\gamma}_2<0$. Объясните принцип, руководствуясь которым легко создать такой набор данных.
\solution{}

\item (?) У меня есть набор данных с выборочным средним $\bar{y}$ и выборочной дисперсией $s^2$. Как нужно преобразовать данные, чтобы выборочное среднее равнялось 7, а выборочная дисперсия --- 9?
\solution{ $y_i^*=7+3(y_i-\bar{y})/s$ }

\end{enumerate}

\section{Теорема Гаусса-Маркова и нормальность}

\begin{enumerate}

\item Напишите формулу для оценок коэффициентов в парной регрессии без матриц

\item Напишите формулу для оценок коэффициентов в множественной регрессии с матрицами

\item (аналогично) для дисперсий

\item Сформулируйте теорему Гаусса-Маркова

\item Ошибки регрессии $\e_i$ независимы и равновероятно принимают значения $+1$ и $-1$. Также известно, что $y_i=\beta \cdot i +\e_i$. Модель оценивается всего по двум наблюдениям. 
\begin{enumerate}
\item Найдите закон распределения $\hb$, $RSS$, $ESS$, $TSS$, $R^2$
\item Найдите $\E(\hb)$, $\Var(\hb)$, $\E(RSS)$, $\E(ESS)$, $\E(R^2)$
\item При каком $\beta$ величина $\E(R^2)$ достигает максимума?
\end{enumerate}
\solution{}

\item По 47 наблюдениям оценивается зависимость доли мужчин занятых в сельском хозяйстве от уровня образованности и доли католического населения по Швейцарским кантонам в 1888 году.

\[Agriculture_i=\beta_1+\beta_2 Examination_i+\beta_3 Catholic_i+\varepsilon_i\]

<<message=FALSE>>=
h <- swiss
model1 <- glm(Agriculture~Examination+Catholic,data=h)
coef.t <- coeftest(model1)
dimnames(coef.t)[[2]] <- 
    c("Оценка","Ст. ошибка",  "t-статистика", "P-значение")
coef.t <- coef.t[,-4]
coef.t[1,1] <- NA
coef.t[2,2] <- NA
coef.t[3,3] <- NA
@

<<results='asis'>>=
xtable(coef.t)
@

\begin{enumerate}
\item Заполните пропуски в таблице
\item Укажите коэффициенты, значимые на 10\% уровне значимости.
\item Постройте 99\%-ый доверительный интервал для коэффициента при переменной Catholic 
\end{enumerate}

Набор данных доступен в пакете R:
<<eval=FALSE>>=
h <- swiss
@
\solution{}


\item Оценивается зависимость уровня фертильности всё тех же швейцарских кантонов в 1888 году от ряда показателей. В таблице представлены результаты оценивания двух моделей.

Модель 1: $Fertility_i=\beta_1+\beta_2 Agriculture_i+\beta_3 Education_i+\beta_4 Examination_i+\beta_5 Catholic_i+\varepsilon_i$

Модель 2: $Fertility_i=\gamma_1+\gamma_2 (Education_i+Examination_i)+\gamma_3 Catholic_i+u_i$

<<>>=
m1 <- lm(Fertility~Agriculture+Education+Examination+Catholic,data=h)
m2 <- lm(Fertility~I(Education+Examination)+Catholic,data=h)
@

<<results='asis'>>=
apsrtable(m1,m2)

@

Набор данных доступен в пакете R:
<<eval=FALSE>>=
h <- swiss
@
\solution{}

<<"load flats", include=FALSE>>=
flats <- read.table("~/science/econometrix/em301/datasets/flats_moscow.txt",header=TRUE)
@
\item По \Sexpr{nrow(flats)} наблюдениям оценена модель зависимости стоимости квартиры в Москве (в 1000\$) от общего метража и метража жилой площади.


<<"flats", results='asis'>>=
model1 <- lm(price~totsp+livesp,data=flats)
report <- summary(model1)
coef.table <- report$coefficients
rownames(coef.table) <- c("Константа","Общая площадь", "Жилая площадь")
xtable(coef.table)
@

Оценка ковариационной матрицы $\widehat{Var}(\hat{\beta})$ имеет вид
<<"var hat", results='asis'>>=
var.hat <- vcov(model1)
xtable(var.hat)
@

\begin{enumerate}
\item Проверьте $H_0$: $\beta_{totsp}=\beta_{livesp}$. В чём содержательный смысл этой гипотезы?
\item Постройте доверительный интервал дли $\beta_{totsp}-\beta_{livesp}$. В чём содержательный смысл этого доверительного интервала?
\end{enumerate}


\solution{
<<include=FALSE>>=
est.se <- sqrt(var.hat[2,2]+var.hat[3,3]-2*var.hat[2,3])
hb <- model1$coefficients
est.diff <- hb[2]-hb[3]
@

Из оценки ковариационной матрицы находим, что $se(\hb_{totsp}=\hb_{livesp})=\Sexpr{est.se}$.

Исходя из $Z_{crit}=1.96$ получаем доверительный интервал, $[\Sexpr{est.diff-1.96*est.se};\Sexpr{est.diff+1.96*est.se}]$.

Вывод: при уровне значимости 5\% гипотеза о равенстве коэффициентов не отвергается.}


\item По \Sexpr{nrow(flats)} наблюдениям оценена модель зависимости стоимости квартиры в Москве (в 1000\$) от общего метража и метража жилой площади.
<<"flats - 2", results='asis'>>=
model1 <- lm(price~totsp+livesp,data=flats)
report <- summary(model1)
coef.table <- report$coefficients
rownames(coef.table) <- c("Константа","Общая площадь", "Жилая площадь")
xtable(coef.table)
@

Оценка ковариационной матрицы $\widehat{Var}(\hat{\beta})$ имеет вид
<<"var hat - 2", results='asis'>>=
xtable(vcov(model1))
@

\begin{enumerate}
\item Постройте 95\%-ый доверительный интервал для ожидаемой стоимости квартиры с жилой площадью $30$ м$^2$ и общей площадью $60$ м$^2$.
\item Постройте 95\%-ый прогнозный интервал для фактической стоимости квартиры с жилой площадью $30$ м$^2$ и общей площадью $60$ м$^2$.
\end{enumerate}


\solution{}

\item Рассмотрим модель с линейным трендом без свободного члена, $y_t=\beta t +\varepsilon_t$. 
\begin{enumerate}
\item Найдите МНК оценку коэффициента $\beta$
\item Рассчитайте $\E(\hat{\beta})$ и $\Var(\hat{\beta})$ в предположениях теоремы Гаусса-Маркова
\item Верно ли, что оценка $\hat{\beta}$ состоятельна?
\end{enumerate}


\solution{
\begin{enumerate}
\item $\hb=\frac{\sum y_t t}{\sum t^2}$
\item $\E(\hat{\beta})=\beta$ и $\Var(\hat{\beta})=\frac{\sigma^2}{\sum_{t=1}^{T} t^2}$
\item Да, состоятельна
\end{enumerate}
}

\item В модели $y_t=\beta_1+\beta_2 x_t$, где 
$x_t=\left\{
\begin{array}{l}
2,\, t=1 \\
1,\, t>1
\end{array}
\right.
$:
\begin{enumerate}
\item Найдите мнк-оценку $\hb_2$
\item Рассчитайте $\E(\hb_2)$ и $\Var(\hb_2)$ в предположениях теоремы Гаусса-Маркова
\item Верно ли, что оценка $\hb_2$ состоятельна?
\end{enumerate}
\solution{}

\item В модели $y_t=\beta_1+\beta_2 x_t$, где 
$x_t=\left\{
\begin{array}{l}
1,\, t=2k+1 \\
0,\, t=2k
\end{array}
\right.
$:
\begin{enumerate}
\item Найдите мнк-оценку $\hb_2$
\item Рассчитайте $\E(\hb_2)$ и $\Var(\hb_2)$ в предположениях теоремы Гаусса-Маркова
\item Верно ли, что оценка $\hb_2$ состоятельна?
\end{enumerate}
\solution{}



\item По \Sexpr{nrow(flats)} наблюдениям оценена модель зависимости стоимости квартиры в Москве (в 1000\$) от общего метража, метража жилой площади и дамми-переменной, равной 1 для кирпичных домов.
<<"flats - 3", results='asis'>>=
model1 <- lm(price~totsp+livesp+brick+brick:totsp+brick:livesp,data=flats)
report <- summary(model1)
coef.table <- report$coefficients
# rownames(coef.table) <- c("Константа","Общая площадь", "Жилая площадь")
xtable(coef.table)
@

\begin{enumerate}
\item Выпишите отдельно уравнения регрессии для кирпичных домов и для некирпичных домов
\item Проинтерпретируйте коэффициент при $brick_i \cdot totsp_i$
\end{enumerate}


\item По 20 наблюдениям оценивается линейная регрессия $\hat{y}=\hat{\beta}_1 +\hat{\beta}_2 x+\hat{\beta}_3 z$, причём истинная зависимость имеет вид $y=\beta_1 +\beta_2 x+\varepsilon$. Случайная ошибка $\varepsilon_i$ имеет нормальное распределение $N(0,1)$.

\begin{enumerate}
\item Найдите вероятность $\P(\hat{\beta}_3>se(\hat{\beta}_3))$
\item Найдите вероятность $\P(\hat{\beta}_3>\sigma_{\hat{\beta}_3})$
\end{enumerate}

\solution{
\begin{enumerate}
\item $\P(\hat{\beta}_3>se(\hat{\beta}_3))=\P(t_{17}>1)=\Sexpr{1-pt(1,17)}$
\item $\P(\hat{\beta}_3>\sigma_{\hat{\beta}_3})=\P(N(0,1)>1)=\Sexpr{1-pnorm(1)}$
\end{enumerate}
}



\item Регрессионная модель  задана в матричном виде при помощи уравнения $y=X\beta+\varepsilon$, где $\beta=(\beta_1,\beta_2,\beta_3)'$.
Известно, что $\E(\varepsilon)=0$  и  $\Var(\varepsilon)=\sigma^2\cdot I$.
Известно также, что 

$y=\left(
\begin{array}{c} 
1\\ 
2\\ 
3\\ 
4\\ 
5
\end{array}\right)$, 
$X=\left(\begin{array}{ccc}
1 & 0 & 0 \\
1 & 0 & 0 \\
1 & 0 & 0 \\
1 & 1 & 0 \\
1 & 1 & 1 
\end{array}\right)$.


Для удобства расчетов приведены матрицы 


$X'X=\left(
\begin{array}{ccc} 
5 & 2 & 1\\ 
2 & 2 & 1\\ 
1 & 1 & 1 
\end{array}\right)$ и $(X'X)^{-1}=\frac{1}{3}\left(
\begin{array}{ccc} 
1 & -1 & 0 \\
-1 & 4 & -3 \\
0 & -3 & 6
\end{array}\right)$.

\begin{enumerate}
\item Укажите число наблюдений.
\item Укажите число регрессоров с учетом свободного члена.
\item Запишите модель в скалярном виде
\item Рассчитайте $TSS=\sum (y_i-\bar{y})^2$, $RSS=\sum (y_i-\hat{y}_i)^2$ и $ESS=\sum (\hat{y}_i-\bar{y})^2$.
\item Рассчитайте при помощи метода наименьших квадратов $\hb$, оценку для вектора неизвестных коэффициентов.
\item Чему равен $\he_5$, МНК-остаток регрессии, соответствующий 5-ому наблюдению?
\item Чему равен $R^2$  в модели? Прокомментируйте полученное значение с точки зрения качества оцененного уравнения регрессии.
\item Используя приведенные выше данные, рассчитайте несмещенную оценку для неизвестного параметра $\sigma^2$ регрессионной модели.
\item Рассчитайте $\widehat{\Var}(\hb)$, оценку для ковариационной матрицы вектора МНК-коэффициентов $\hb$.  
\item Найдите $\widehat{\Var}(\hb_1)$, несмещенную оценку дисперсии МНК-коэффициента $\hb_1$.
\item Найдите $\widehat{\Var}(\hb_2)$, несмещенную оценку дисперсии МНК-коэффициента $\hb_2$.
\item Найдите $\widehat{\Cov}(\hb_1,\hb_2)$, несмещенную оценку ковариации МНК-коэффициентов $\hb_1$ и $\hb_2$.
\item Найдите $\widehat{\Var}(\hb_1+\hb_2)$, $\widehat{\Var}(\hb_1-\hb_2)$, $\widehat{\Var}(\hb_1+\hb_2+\hb_3)$, $\widehat{\Var}(\hb_1+\hb_2-2\hb_3)$
\item Найдите $\hCorr(\hb_1,\hb_2)$, оценку коэффициента корреляции МНК-коэффициентов $\hb_1$ и $\hb_2$.
\item Найдите $s_{\hb_1}$, стандартную ошибку МНК-коэффициента $\hb_1$.
\item Рассчитайте выборочную ковариацию $y$ и $\hy$.
\item Найдите выборочную дисперсию $y$, выборочную дисперсию $\hy$.
\end{enumerate}

\item Априори известно, что парная регрессия должна проходить через точку $(x_{0},y_{0})$.
\begin{enumerate}
\item  Выведите формулы МНК оценок;
\item В предположениях теоремы Гаусса-Маркова найдите дисперсии и средние оценок 
\end{enumerate}

\solution{Вроде бы равносильно переносу начала координат и применению результата для регрессии без свободного члена. Должна остаться несмещенность. }

\item Мы предполагаем, что $y_t$ растёт с линейным трендом, т.е. $y_t=\b_1+\b_2 t+\e_t$. Все предпосылки теоремы Гаусса-Маркова выполнены. В качестве оценки $\hb_2$ предлагается $\hb_2=\frac{Y_T-1}{T-1}$, где $T$ --- общее количество наблюдений. 
\begin{enumerate}
\item Найдите $\E(\hb_2)$ и $\Var(\hb_2)$
\item Совпадает ли оценка $\hb_2$ с классической мнк-оценкой?
\item У какой оценки дисперсия выше, у $\hb_2$ или классической мнк-оценки?
\end{enumerate}

\item Сгенерировать набор данных, обладающий следующим свойством. Если попытаться сразу выкинуть регрессоры $x$ и $z$, то гипотеза о их совместной незначимости отвергается. Если вместо этого попытаться выкинуть отдельно $x$, или отдельно $z$, то гипотеза о незначимости не отвергается.
\solution{Сгенерировать сильно коррелированные $x$ и $z$}

\item Вася считает, что выборочная ковариация $\sCov(y,\hy)=\frac{\sum (y_i-\bar{y})(\hy_i-\bar{y})}{n-1}$ это неплохая оценка для $\Cov(y_i,\hy_i)$. Прав ли он?
\solution{Не прав. Ковариация $\Cov(y_i,\hy_i)$ зависит от $i$, это не одно неизвестное число, для которого можно предложить одну оценку.}


\item Сгенерировать набор данных, обладающий следующим свойством. Если попытаться сразу выкинуть регрессоры $x$ и $z$, то гипотеза о их совместной незначимости отвергается. Если вместо сначала выкинуть отдельно $x$, то гипотеза о незначимости не отвергается. Если затем выкинуть $z$, то гипотезы о незначимости тоже не отвергается.
\solution{??}

\item К эконометристу Вовочке в распоряжение попали данные с результатами контрольной работы студентов по эконометрике. В данных есть результаты по каждой задаче, переменные $p_1$, $p_2$, $p_3$, $p_4$ и $p_5$, и суммарный результат за контрольную, переменная $kr$. Чему будут равны оценки коэффициентов, их стандартные ошибки, t-статистики, P-значения, $R^2$, $RSS$, если
\begin{enumerate}
\item Вовочка построит регрессию $kr$ на константу, $p_1$, $p_2$, $p_3$, $p_4$ и $p_5$
\item Вовочка построит регрессию $kr$ на $p_1$, $p_2$, $p_3$, $p_4$ и $p_5$ без константы
\end{enumerate}
\solution{}


\item Про $R^2_{adj}$
\begin{enumerate}
\item Может ли в модели с константой $R^2_{adj}$ быть отрицательным?
\item Что больше, $R^2$ или $R^2_{adj}$ в модели с константой?
\item Вася оценил модель $A$, а затем выкинул из нее регрессор $z$ и оценил получившуюся модель $B$. В моделях $A$ и $B$ оказались равные $R^2_{adj}$. Чему равна $t$-статистика коэффициента при $z$ в модели $A$?
\item Есть две модели с одной и той же зависимой переменной, но с разными объясняющими переменными, модель $A$ и модель $B$. В модели $A$ коэффициент $R^2_{adj}$ больше, чем в модели $B$. В какой из моделей больше коэффициент $\hat{\sigma^2}$? 
\end{enumerate}
\solution{да, $R^2$, $t=1$, $B$ }

\item Сгенерируйте данные так, чтобы при оценке линейной регрессионной модели оказалось, что скорректированный коэффициент детерминации, $R^2_{adj}$, отрицательный.



\[ R^2_{adj}=1-(1-R^2)\frac{n-1}{n-k} \]

Следовательно, при $R^2$ близком к 0 и большом количестве регрессоров $k$ может оказаться, что $R^2_{adj}<0$. 

Например,
<<"negative adjusted R^2">>=
set.seed(42)
y <- rnorm(200,sd=15)
X <- matrix(rnorm(2000),nrow=200)
model <- lm(y~X)
report <- summary(model)
report$adj.r.squared
@
\solution{ }
\todo[inline]{Косяк. Почему-то книтр внутри solution ругается на доллар.}


\item В классической линейной регрессионной модели $y_i=\beta_1+\beta_2 x_i+\e_i$, дисперсия зависимой переменной не зависит от номера наблюдения, $\Var(y_i)=\sigma^2$. Почему для оценки $\sigma^2$ вместо известной из курса математической статистики формулы $\sum (y_i-\bar{y})^2/(n-1)$ используют $\sum \he_i^2/(n-2)$?
\solution{формула $\sum (y_i-\bar{y})^2/(n-1)$ неприменима так как $\E(y_i)$ не является константой }


\item Оценка регрессии имеет вид $\hy_i=3-2x_i$. Выборочная дисперсия $x$ равна $9$, выборочная дисперсия $y$ равна $40$. Найдите $R^2$ и выборочные корреляции $\sCorr(x,y)$, $\sCorr(y,\hy)$.
\solution{$R^2$ --- это отношение выборочных дисперсий $\hy$ и $y$. } 

\item \problem{ Слитки-вариант. Перед нами два золотых слитка и весы, производящие взвешивания с ошибками. Взвесив первый слиток, мы получили результат $300$ грамм, взвесив второй слиток --- $200$ грамм, взвесив оба слитка --- $400$ грамм. Предположим, что ошибки взвешивания --- независимые одинаково распределенные случайные величины с нулевым средним. 
\begin{enumerate}
\item Найдите несмещеную оценку веса первого шара, обладающую наименьшей дисперсией.
\item Как можно проинтерпретировать нулевое математическое ожидание ошибки взвешивания? 
\end{enumerate} }
\solution{ Как отсутствие систематической ошибки.} 


\item Скачайте результаты двух контрольных работ по теории вероятностей, \url{} с описанием данных, \url{}. Наша задача попытаться предсказать результат второй контрольной работы зная позадачный результат первой контрольной, пол и группу студента. 
\begin{enumerate}
\item Какая задача из первой контрольной работы наиболее существенно влияет на результат второй контрольной?
\item Влияет ли пол на результат второй контрольной?
\item Влияет ли редкость имени на результат второй контрольной?
\item Что можно сказать про влияние группы, в которой учится студент?
\end{enumerate}
\solution{}


\item Напишите свою функцию, которая бы оценивала регрессию методом наименьших квадратов. На вход функции должны подаваться вектор зависимых переменных $y$ и матрица регрессоров $X$. На выходе функция должна выдавать список из $\hb$, $\hVar(\hb)$, $\hy$, $\he$, $ESS$, $RSS$ и $TSS$. По возможности функция должна проверять корректность аргументов, например, что в $y$ и $X$ одинаковое число наблюдений и т.д. Использовать \verb|lm| или \verb|glm| запрещается.
\solution{}



\item Сгенерируйте вектор $y$ из 300 независимых нормальных $N(10,1)$ случайных величин. Сгенерируйте 40 <<объясняющих>> переменных, по 300 наблюдений в каждой, каждое наблюдение --- независимая нормальная $N(5,1)$ случайная величина. Постройте регрессию $y$ на все 40 регрессоров и константу. 
\begin{enumerate}
\item Сколько регрессоров оказалось значимо на 5\% уровне?
\item Сколько регрессоров в среднем значимо на 5\% уровне?
\item Эконометрист Вовочка всегда использует следующий подход: строит регрессию зависимой переменной на все имеющиеся регрессоры, а затем выкидывает из модели те регрессоры, которые оказались незначимы. Прокомментируйте Вовочкин эконометрический подход.
\end{enumerate}
\solution{}


\item Мы попытаемся понять, как введение в регрессию лишнего регрессора влияет на оценки уже имеющихся. В регрессии будет 100 наблюдений. Возьмем $\rho=0.5$. Сгенерим выборку совместных нормальных $x_i$ и $z_i$ с корреляцией $\rho$. Настоящий $y_i$ задаётся формулой $y_i=5+6x_i+\e_i$. Однако мы будем оценивать модель $\hy_i=\hb_1+\hb_2 x_i+\hb_3 z_i$.

\begin{enumerate}
\item Повторите указанный эксперимент 500 раз и постройте оценку для функции плотности $\hb_1$. 
\item Повторите указанный эксперимент 500 раз для каждого $\rho$ от $-1$ до $1$ с шагом в $0.05$. Каждый раз сохраняйте полученные 500 значений $\hb_1$. В осях $(\rho,\hb_1)$ постройте 95\%-ый предиктивный интервал для $\hb_1$. Прокомментируйте.
\end{enumerate}
\solution{}

\item Цель задачи --- оценить модель CAPM несколькими способами. 
\begin{enumerate}
\item Соберите подходящие данные для модели CAPM. Нужно найти три временных ряда: ряд цен любой акции, любой рыночный индекс, безрисковый актив. Переведите цены в доходности.
\item Постройте графики
\item Оцените модель CAPM без свободного члена по всем наборам данных. Прокомментируйте смысл оцененного коэффициента
\item Разбейте временной период на два участка и проверьте устойчивость коэффициента бета
\item Добавьте в классическую модель CAPM свободный член и оцените по всему набору данных. Какие выводы можно сделать? 
\item Методом максимального правдоподобия оцените модель с ошибкой измерения $R^m-R^0$, т.е.

истинная зависимость имеет вид 
\begin{equation}
(R^s-R^0)=\b_1+\b_2(R_m^*-R_0^*)+\e
\end{equation}
величины $R_m^*$ и $R_0^*$ не наблюдаемы, но 
\begin{equation}
R_m-R_0=R_m^*-R_0^*+u
\end{equation}

\end{enumerate}

\item Как построить доверительный интервал для вершины параболы? ...
\solution{bootstrap, дельта-метод}
% Спросить Лену



\end{enumerate}


\section{Мультиколлинеарность}


\begin{enumerate}
\item Сгенерируйте данные так, чтобы при оценке модели $\hat{y}=\hat{\beta_1}+\hat{\beta_2}x+\hat{\beta_3}z$ оказывалось, что по отдельности оценки коэффициентов $\hat{\beta_2}$ и $\hat{\beta_3}$ незначимы, но модель в целом --- значима.
\solution{}

\item В этом задании нужно сгенерировать зависимую переменную $y$ и два регрессора $x$ и $z$.
\begin{enumerate}
\item Сгенерируйте данные так, чтобы корреляция между регрессорами $x$ и $z$ была больше $0.9$, и проблема мультиколлинеарности есть, т.е. по отдельности регрессоры не значимы, но регрессия в целом --- значима.
\item А теперь сгенерируйте данные так, чтобы корреляция между регрессорами была по-прежнему больше $0.9$, но проблемы мультиколлинеарности бы не было, т.е. все коэффициенты были бы значимы.
\item Есть несколько способов, как изменить генерации случайных величин, чтобы перейти от ситуации <<a>> к ситуации <<b>>. Назовите хотя бы два.   
\end{enumerate}
\solution{увеличить количество наблюдений, уменьшить дисперсию случайной ошибки}

\item Исследуем зависимость длины тормозного пути автомобиля от скорости по историческим данным 1920-х годов.


<<message=FALSE>>=
h <- cars
ggplot(h,aes(x=speed,y=dist))+geom_point()+
    labs(title="Зависимость длины тормозного пути",
    x="Скорость, миль в час",y="Длина пути, футов")
speed.mean <- mean(h$speed)
@

Построим результаты оценивания нецентрированной регрессии:
<<>>=
cars.model <- lm(dist~speed+I(speed^2)+I(speed^3),data=h)
cars.table <- as.table(coeftest(cars.model))
rownames(cars.table) <-c("Константа","speed","speed^2","speed^3")
@

\todo[inline]{с тремя переменными руками громоздко делать, а с двумя вроде не видно мультик.}

<<results='asis'>>=
xtable(cars.table)
@

Ковариационная матрица коэффициентов имеет вид:
<<results='asis'>>=
cars.vcov <- vcov(cars.model)
rownames(cars.vcov) <-c("Константа","speed","speed^2","speed^3")
colnames(cars.vcov) <-c("Константа","speed","speed^2","speed^3")
xtable(cars.vcov)
@

\begin{enumerate}
\item Проверьте значимость всех коэффициентов и регрессии в целом
\item Постройте 95\%-ый доверительный интервал для $\E(dist)$ при $speed=10$
\item Постройте 95\%-ый доверительный интервал для $\E(ddist/dspeed)$ при $speed=10$
\item Как выглядит уравнение регрессии, если вместо $speed$ использовать центрированную скорость? Известно, что средняя скорость равна $\Sexpr{speed.mean}$
\item С помощью регрессии с центрированной скоростью ответьте на предыдущие вопросы.
\end{enumerate}



\item Пионеры, Крокодил Гена и Чебурашка собирали металлолом несколько дней подряд. В распоряжение иностранной шпионки, гражданки Шапокляк, попали ежедневные данные по количеству собранного металлолома: вектор $g$ --- для Крокодила Гены, вектор $h$ --- для Чебурашки и вектор $x$ --- для Пионеров. Гена и Чебурашка собирали вместе, поэтому выборочная корреляция $\sCorr(g,h)=-0.9$. Гена и Чебурашка собирали независимо от Пионеров, поэтому выборочные корреляции $\sCorr(g,x)=0$, $\sCorr(h,x)=0$. Если регрессоры $g$, $h$ и $x$ центрировать и нормировать, то получится матрица $\tilde{X}$.
\begin{enumerate}
\item Найдите параметр обусловленности матрицы $(\tilde{X}'\tilde{X})$
\item Вычислите одну или две главные компоненты (выразите их через вектор-столбцы матрицы $\tilde{X}$), объясняющие не менее 70\% общей выборочной дисперсии регрессоров
\item Шпионка Шапокляк пытается смоделировать ежедневный выпуск танков, $y$. Выразите коэффициенты регрессии $y = \beta_1 + \beta_2 g +\beta_3 h +\beta_4 x+\varepsilon$ через коэффициенты регрессии на главные компоненты, объясняющие не менее 70\% общей выборочной дисперсии. 
\end{enumerate}
\solution{}



\item Для модели $y_i=\beta x_i+\e$ рассмотрите модель Ridge regression с коэффициентом $\lambda$.
\begin{enumerate}
\item Выведите формулу для $\hb_{RR}$
\item Найдите $\E(\hb_{RR})$, смещение оценки $\hb_{RR}$,
\item Найдите $\Var(\hb_{RR})$, $MSE(\hb_{RR})$
\item Всегда ли оценка $\hb_{RR}$ смещена?
\item Всегда ли оценка $\hb_{RR}$ имеет меньшую дисперсию, чем $\hb_{ols}$?
\item Найдите такое $\lambda$, что $MSE(\hb_{RR})<MSE(\hb_{ols})$
\end{enumerate}
\solution{}


\item Известно, что в модели $y=X\beta+\e$ все регрессоры ортогональны. 
\begin{enumerate}
\item Как выглядит матрица $X'X$ в случае ортогональных регрессоров?
\item Выведите $\hb_{rr}$ в явном виде
\item Как связаны между собой $\hb_{rr}$ и $\hb_{ols}$?
\end{enumerate}
\solution{}

\item Для модели $y_i=\beta x_i + \e_i$ выведите в явном виде $\hb_{lasso}$.
\solution{}

\end{enumerate}


\section{Гетероскедастичность}

\begin{enumerate}

\item Что такое гетероскедастичность? Гомоскедастичность?

\item Диаграмма рассеяния стоимости квартиры в Москве (в 1000\$) и общей площади квартиры имеет вид:

<<"diagram", warning=FALSE>>=
ggplot(flats,aes(x=totsp,y=price))+geom_point()+
    labs(x="Общая площадь, кв. м.",y="Цена квартиры, 1000$")
@

Какие подходы к оцениванию зависимости имеет смысл посоветовать исходя из данного графика?

\solution{
По графику видно, что с увеличением общей площади увеличивается разброс цены. Поэтому разумно, например, рассмотреть следующие подходы:
\begin{enumerate}
\item Перейти к логарифмам, т.е. оценивать модель $\ln price_i=\beta_1+\beta_2 \ln totsp_i +\varepsilon_i$
\item Оценивать квантильную регрессию. В ней угловые коэффициенты линейной зависимости будут отличаться для разных квантилей переменной $price$.
\item Обычную модель линейной регрессии с гетероскедастичностью вида $Var(\varepsilon_i)=\sigma^2 totsp_i^2$
\end{enumerate} 
}


\item По наблюдениям $x=(1,2,3)'$, $y=(2,-1,3)'$ оценивается модель $y=\b_1+\b_2 x+\e$. Ошибки $\e$ гетероскедастичны и известно, что $\Var(\e_i)=\sigma^2 \cdot x_i^2$. 
\begin{enumerate}
\item Найдите оценки $\hb_{ols}$ с помощью МНК и их ковариационную матрицу
\item Найдите оценки $\hb_{gls}$ с помощью обобщенного МНК и их ковариационную матрицу 
\end{enumerate}  
\solution{}


\item В модели $y=\hb_1+\hb_2 x+\e$ присутствует гетероскедастичность вида $\Var(\e_i)=\sigma^2 x^2_i$. Как надо преобразовать исходные регрессоры и зависимую переменную, чтобы устранить гетероскедастичность? 
\solution{Поделить зависимую переменную и каждый регрессор, включая единичный столбец, на $|x_i|$.}

\item В модели $y=\hb_1+\hb_2 x+\e$ присутствует гетероскедастичность вида $\Var(\e_i)=\lambda |x_i|$. Как надо преобразовать исходные регрессоры и зависимую переменную, чтобы устранить гетероскедастичность? 
\solution{Поделить зависимую переменную и каждый регрессор, включая единичный столбец, на $\sqrt{|x_i|}$.}

\item Известно, что после деления каждого уравнения регрессии $y_i = \beta_1 + \beta_2 x_i + \e_i$ на $x_i^2$ гетероскедастичность ошибок была устранена. Какой вид имела дисперсия ошибок, $\Var(\e_i)$?
\solution{$\Var(\e_i)=cx_i^4$}

\item Известно, что после деления каждого уравнения регрессии $y_i = \beta_1 + \beta_2 x_i + \e_i$ на $\sqrt{x_i}$ гетероскедастичность ошибок была устранена. Какой вид имела дисперсия ошибок, $\Var(\e_i)$?
\solution{$\Var(\e_i)=c x_i$}

\item Для линейной регрессии $y_i = \beta_1 + \beta_2 x_i + \beta_3 z_i + \e_i$ была
выполнена сортировка наблюдений по возрастанию переменной $x$. Исходная модель оценивалась по разным частям выборки:

\begin{tabular}{|c|c|c|c|c|}
\hline 
Выборка & $\hb_1$ & $\hb_2$ & $\hb_3$ & $RSS$ \\

\hline 
$i=1,\ldots, 30$ & $1.21$ & $1.89$ & $2.74$ & $48.69$ \\ 
\hline 
$i=1,\ldots, 11$ & $1.39$ & $2.27$ & $2.36$ & $10.28$ \\ 
\hline 
$i=12,\ldots, 19$ & $0.75$ & $2.23$ & $3.19$ & $5.31$ \\ 
\hline 
$i=20,\ldots, 30$ & $1.56$ & $1.06$ & $2.29$ & $14.51$ \\ 
\hline 
\end{tabular} 

Известно, что ошибки в модели являются независимыми нормальными случайными величинами с нулевым математическим ожиданием. Протестируйте
ошибки на гетероскедастичность на уровне значимости 5\%.

\solution{Протестируем гетероскедастичность ошибок при помощи теста Голдфельда-
Квандта. $H_0: \Var(\e_i)=\sigma^2$, $H_a: \Var(\e_i)=f(x_i)$

\begin{enumerate}
\item Тестовая статистика $GQ=\frac{RSS_3/(n_3-k)}{RSS_1/(n_1-k)}$, где $n_1=11$ --- число наблюдений в первой подгруппе, $n_3=11$ --- число наблюдений в
последней подгруппе, $k=3$ --- число факторов в модели, считая единичный столбец.
\item Распределение тестовой статистики при верной $H_0$: $GQ\sim F_{n_3-k,n_1-k}$
\item Наблюдаемое значение $GQ_{obs}=1.41$
\item Область в которой $H_0$ не отвергается: $GQ\in [0;3.44]$
\item Статистический вывод: поскольку $GQ_{obs} \in [0;3.44]$, то на основании имеющихся наблюдений на уровне значимости 5\% основная гипотеза $H_0$ не может быть отвергнута. Таким образом, тест Голдфельда-Квандта не выявил гетероскедастичность.
\end{enumerate} 
}

\item Для линейной регрессии $y_i = \beta_1 + \beta_2 x_i + \beta_3 z_i + \e_i$ была
выполнена сортировка наблюдений по возрастанию переменной $x$. Исходная модель оценивалась по разным частям выборки:

\begin{tabular}{|c|c|c|c|c|}
\hline 
Выборка & $\hb_1$ & $\hb_2$ & $\hb_3$ & $RSS$ \\

\hline 
$i=1,\ldots, 50$ & $1.16$ & $1.99$ & $2.97$ & $174.69$ \\ 
\hline 
$i=1,\ldots, 21$ & $0.76$ & $2.25$ & $3.18$ & $20.41$ \\ 
\hline 
$i=22,\ldots, 29$ & $0.85$ & $1.81$ & $3.32$ & $3.95$ \\ 
\hline 
$i=30,\ldots, 50$ & $1.72$ & $1.41$ & $2.49$ & $130.74$ \\ 
\hline 
\end{tabular} 

Известно, что ошибки в модели являются независимыми нормальными случайными величинами с нулевым математическим ожиданием. Протестируйте
ошибки на гетероскедастичность на уровне значимости 1\%.

\solution{Протестируем гетероскедастичность ошибок при помощи теста Голдфельда-
Квандта. $H_0: \Var(\e_i)=\sigma^2$, $H_a: \Var(\e_i)=f(x_i)$

\begin{enumerate}
\item Тестовая статистика $GQ=\frac{RSS_3/(n_3-k)}{RSS_1/(n_1-k)}$, где $n_1=21$ --- число наблюдений в первой подгруппе, $n_3=21$ --- число наблюдений в
последней подгруппе, $k=3$ --- число факторов в модели, считая единичный столбец.
\item Распределение тестовой статистики при верной $H_0$: $GQ\sim F_{n_3-k,n_1-k}$
\item Наблюдаемое значение $GQ_{obs}=6.49$
\item Область в которой $H_0$ не отвергается: $GQ\in [0;3.12]$
\item Статистический вывод: поскольку $GQ_{obs} \notin [0;3.12]$, то на основании имеющихся наблюдений на уровне значимости 1\% основная гипотеза $H_0$ отвергается. Таким образом, тест Голдфельда-Квандта выявил гетероскедастичность.
\end{enumerate} 
}

\item Для линейной регрессии $y_i = \beta_1 + \beta_2 x_i + \beta_3 z_i + \e_i$ была
выполнена сортировка наблюдений по возрастанию переменной $x$. Исходная модель оценивалась по разным частям выборки:

\begin{tabular}{|c|c|c|c|c|}
\hline 
Выборка & $\hb_1$ & $\hb_2$ & $\hb_3$ & $RSS$ \\

\hline 
$i=1,\ldots, 30$ & $0.96$ & $2.25$ & $3.44$ & $52.70$ \\ 
\hline 
$i=1,\ldots, 11$ & $1.07$ & $2.46$ & $2.40$ & $5.55$ \\ 
\hline 
$i=12,\ldots, 19$ & $1.32$ & $1.01$ & $2.88$ & $11.69$ \\ 
\hline 
$i=20,\ldots, 30$ & $1.04$ & $2.56$ & $4.12$ & $16.00$ \\ 
\hline 
\end{tabular} 

Известно, что ошибки в модели являются независимыми нормальными случайными величинами с нулевым математическим ожиданием. Протестируйте
ошибки на гетероскедастичность на уровне значимости 5\%.

\solution{Протестируем гетероскедастичность ошибок при помощи теста Голдфельда-
Квандта. $H_0: \Var(\e_i)=\sigma^2$, $H_a: \Var(\e_i)=f(x_i)$

\begin{enumerate}
\item Тестовая статистика $GQ=\frac{RSS_3/(n_3-k)}{RSS_1/(n_1-k)}$, где $n_1=11$ --- число наблюдений в первой подгруппе, $n_3=11$ --- число наблюдений в
последней подгруппе, $k=3$ --- число факторов в модели, считая единичный столбец.
\item Распределение тестовой статистики при верной $H_0$: $GQ\sim F_{n_3-k,n_1-k}$
\item Наблюдаемое значение $GQ_{obs}=2.88$
\item Область в которой $H_0$ не отвергается: $GQ\in [0;3.44]$
\item Статистический вывод: поскольку $GQ_{obs} \in [0;3.44]$, то на основании имеющихся наблюдений на уровне значимости 5\% основная гипотеза $H_0$ не может быть отвергнута. Таким образом, тест Голдфельда-Квандта не выявил гетероскедастичность.
\end{enumerate} 
}


\item Для линейной регрессии $y_i = \beta_1 + \beta_2 x_i + \beta_3 z_i + \e_i$ была
выполнена сортировка наблюдений по возрастанию переменной $x$. Исходная модель оценивалась по разным частям выборки:

\begin{tabular}{|c|c|c|c|c|}
\hline 
Выборка & $\hb_1$ & $\hb_2$ & $\hb_3$ & $RSS$ \\

\hline 
$i=1,\ldots, 50$ & $0.93$ & $2.02$ & $3.38$ & $145.85$ \\ 
\hline 
$i=1,\ldots, 21$ & $1.12$ & $2.01$ & $3.32$ & $19.88$ \\ 
\hline 
$i=22,\ldots, 29$ & $0.29$ & $2.07$ & $2.24$ & $1.94$ \\ 
\hline 
$i=30,\ldots, 50$ & $0.87$ & $1.84$ & $3.66$ & $117.46$ \\ 
\hline 
\end{tabular} 

Известно, что ошибки в модели являются независимыми нормальными случайными величинами с нулевым математическим ожиданием. Протестируйте
ошибки на гетероскедастичность на уровне значимости 5\%.

\solution{Протестируем гетероскедастичность ошибок при помощи теста Голдфельда-
Квандта. $H_0: \Var(\e_i)=\sigma^2$, $H_a: \Var(\e_i)=f(x_i)$

\begin{enumerate}
\item Тестовая статистика $GQ=\frac{RSS_3/(n_3-k)}{RSS_1/(n_1-k)}$, где $n_1=21$ --- число наблюдений в первой подгруппе, $n_3=21$ --- число наблюдений в
последней подгруппе, $k=3$ --- число факторов в модели, считая единичный столбец.
\item Распределение тестовой статистики при верной $H_0$: $GQ\sim F_{n_3-k,n_1-k}$
\item Наблюдаемое значение $GQ_{obs}=5.91$
\item Область в которой $H_0$ не отвергается: $GQ\in [0;2.21]$
\item Статистический вывод: поскольку $GQ_{obs} \notin [0;2.21]$, то на основании имеющихся наблюдений на уровне значимости 5\% основная гипотеза $H_0$ отвергается. Таким образом, тест Голдфельда-Квандта выявил гетероскедастичность.
\end{enumerate} 
}

\item Рассмотрим линейную регрессию $y_i = \beta_1 + \beta_2 x_i + \beta_3 z_i + \e_i$. При оценивании с помощью МНК были получены результаты: $\hb_1=1.21$, $\hb_2=1.11$, $\hb_3=3.15$, $R^2=0.72$.

Оценена также вспомогательная регрессия: $\he_i=\delta_1+\delta_2 x_i +\delta_3 z_i+\delta_4 x_i^2+\delta_5 z_i^2+\delta_6 x_i z_i + u_i$. Результаты оценивания следующие: $\hat{\delta}_1=1.50$, $\hat{\delta}_2=-2.18$,  $\hat{\delta}_3=0.23$,  $\hat{\delta}_4=1.87$,  $\hat{\delta}_5=-0.56$,  $\hat{\delta}_6=-0.09$,  $R^2_{aux}=0.36$ 


Известно, что ошибки в модели являются независимыми нормальными случайными величинами с нулевым математическим ожиданием. Протестируйте
ошибки на гетероскедастичность на уровне значимости 5\%.

\solution{ Протестируем гетероскедастичность ошибок при помощи теста Уайта. $H_0: \Var(\e_i)=\sigma^2$, $H_a: \Var(\e_i)=\delta_1+\delta_2 x_i +\delta_3 z_i+\delta_4 x_i^2+\delta_5 z_i^2+\delta_6 x_i z_i$.
\begin{enumerate}
\item Тестовая статистика $W=n\cdot R^2_{aux}$, где $n$ --- число наблюдений, $R^2_{aux}$ --- коэффициент детерминации для вспомогательной регрессии.
\item Распределение тестовой статистики при верной $H_0$: $W\sim \chi^2_{k_{aux}-1}$, где $k_{aux}=6$ --- число регрессоров во вспомогательной регрессии, считая константу.
\item Наблюдаемое значение тестовой статистики: $W_{obs}=18$
\item Область в которой $H_0$ не отвергается: $W\in [0;W_{crit}]=[0;11.07]$
\item Статистический вывод: поскольку $GQ_{obs} \notin [0;11.07]$, то на основании имеющихся наблюдений на уровне значимости 5\% основная гипотеза $H_0$ отвергается. Таким образом, тест Уайта выявил гетероскедастичность.
\end{enumerate}
}

\end{enumerate}


\section{Временные ряды}

\begin{enumerate}
\item Что такое автокорреляция?


\item На графике представлены данные по уровню озера Гур\'{о}н в футах в 1875-1972 годах:  

<<include=FALSE>>=
library(zoo)
library(tseries)
library(ggplot2)
level <- LakeHuron
df <- data.frame(level,obs=1875:1972)
v.acf <- acf(level,plot=FALSE)$acf
v.pacf <- pacf(level,plot=FALSE)$acf
acfs.df <- data.frame(lag=c(1:15,1:15),
    acf=c(v.acf[2:16],v.pacf[1:15]),
    acf.type=rep(c("ACF","PACF"),each=15))
model <- arima(level,order=c(1,0,1))
resids <- model$residuals
resid.acf <- acf(resids,plot=FALSE)$acf
@

<<warning=FALSE,message=FALSE,out.height="6cm",out.width="6cm">>=
ggplot(df,aes(x=obs,y=level))+geom_line()+
    labs(x="Год",ylab="Уровень озера (футы)")
@

График автокорреляционной и частной автокорреляционной функций:

<<warning=FALSE,out.height="6cm",out.width="6.5cm">>=
ggplot(acfs.df,aes(x=lag,y=acf,fill=acf.type))+
    geom_histogram(position="dodge",stat="identity")+
  xlab("Лаг")+ylab("Корреляция") +
  guides(fill=guide_legend(title=NULL))+
  geom_hline(yintercept=1.96/sqrt(nrow(df)))+
  geom_hline(yintercept=-1.96/sqrt(nrow(df)))
@


\begin{enumerate}
\item Судя по графикам, какие модели класса ARMA или ARIMA имеет смысл оценить?
\item По результатам оценки некоей модели ARMA c двумя параметрами, исследователь посчитал оценки автокорреляционной функции для остатков модели. Известно, что для остатков модели первые три выборочные автокорреляции равны соответственно $\Sexpr{resid.acf[2]}$, $\Sexpr{resid.acf[3]}$ и $\Sexpr{resid.acf[4]}$. С помощью подходящей статистики проверьте гипотезу о том, что первые три корреляции ошибок модели равны нулю.
\end{enumerate}




\item Винни-Пух пытается выявить закономерность в количестве придумываемых им каждый день ворчалок.  Винни-Пух решил разобраться, является ли оно стационарным процессом, для этого он оценил регрессию

\[ \Delta \hat{y}_t = \underset{(0.5)}{4.5} - \underset{(0.1)}{0.4}y_{t-1} +\underset{(0.5)}{0.7} \Delta y_{t-1} \]

Из-за опилок в голове Винни-Пух забыл, какой тест ему нужно провести, то ли Доктора Ватсона, то ли Дикого Фуллера. 

\begin{enumerate}
\item Аккуратно сформулируйте основную и альтернативную гипотезы
\item Проведите подходящий тест на уровне значимости 5\%
\item Сделайте вывод о стационарности ряда
\item Почему Сова не советовала Винни-Пуху пользоваться широко применяемой в Лесу $t$-статистикой?
\end{enumerate}

\end{enumerate}



\section{Функциональная форма}

\begin{enumerate}
\item Сгенерируйте данные так, чтобы при оценке модели $\hat{y}=\hat{\beta_1}+\hat{\beta_2}x+\hat{\beta_3}z$ оказывалось, что $\hat{\beta_2}>0$, а при оценке модели $\hat{y}=\hat{\beta_1}+\hat{\beta_2}x$ оказывалось, что $\hat{\beta_2}<0$.
\end{enumerate}



\section{Инструментальные переменные}


Экзогенность, $\E(\e\mid x)=0$


Предопределённость, $\E(\e_t\mid x_t)=0$ для всех $t$

\begin{enumerate}
\item Табличка 2 на 2. Найдите $\E(\varepsilon)$, $\E(\varepsilon|x)$, $\Cov(\varepsilon,x)$.
\solution{}

\item Приведите примеры дискретных случайных величин $\e$ и $x$, таких, что
\begin{enumerate}
\item $\E(\e)=0$, $\E(\e\mid x)=0$, но величины зависимы. Чему в этом случае равно $\Cov(\e,x)$?
\item $\E(\e)=0$, $\Cov(\e,x)=0$, но $\E(\e\mid x)\neq 0$. Зависимы ли эти случайные величины? 
\end{enumerate}
\solution{}

\item Все предпосылки классической линейной модели выполнены, $y=\beta_1+\beta_2 x+\varepsilon$. Рассмотрим альтернативную оценку коэффициента $\beta_2$,
\begin{equation}
\hb_{2,IV}=\frac{\sum z_i(y_i-\bar{y})}{\sum z_i(x_i-\bar{x})}
\end{equation}
\begin{enumerate}
\item Является ли оценка несмещенной?
\item Любые ли $z_i$ можно брать?
\item Найдите $\Var(\hb_{2,IV})$
\end{enumerate}
\solution{Да, является. Любые, кроме констант. $\Var(\hb_{2,IV})=\sigma^2 \sum (z_i-\bar{z})^2/ \left(\sum (z_i-\bar{z})x_i \right)^2 $.}

\item 
\end{enumerate}


\section{Проекция, Картинка}
\begin{enumerate}
\item Найдите на Картинке все перпендикулярные векторы. Найдите на Картинке все прямоугольные треугольники. Сформулируйте для них теоремы Пифагора.
\solution{$\sum y_i^2=\sum \hy_i^2+\sum \he_i^2$, $TSS=ESS+RSS$, }

\item Покажите на Картинке TSS, ESS, RSS, $R^2$, $\sCov(\hy,y)$
\solution{}


\item Предложите аналог $R^2$ для случая, когда константа среди регрессоров отсутствует. Аналог должен быть всегда в диапазоне $[0;1]$, совпадать с обычным $R^2$, когда среди регрессоров есть константа, равняться единице в случае нулевого $\he$.
\solution{Спроецируем единичный столбец на <<плоскость>>, обозначим его $1'$. Делаем проекцию $y$ на <<плоскость>> и на $1'$. Далее аналогично. }

\item Вася оценил регрессию $y$ на константу, $x$ и $z$. А затем, делать ему нечего, регрессию $y$ на константу и полученный $\hy$. Какие оценки коэффициентов у него получатся? Чему будет равна оценка дисперсии коэффицента при $\hy$? Почему оценка коэффициента неслучайна, а оценка её дисперсии положительна?
\solution{Проекция $y$ на $\hy$ это $\hy$, поэтому оценки коэффициентов будут 0 и 1. Оценка дисперсии $\frac{RSS}{(n-2)ESS}$. Нарушены предпосылки теоремы Гаусса-Маркова, например, ошибки новой модели в сумме дают 0, значит коррелированы. } 


\item При каких условиях $TSS=ESS+RSS$?
\solution{Либо в регрессию включена константа, либо единичный столбец (тут была опечатка, столбей) можно получить как линейную комбинацию регрессоров, например, включены дамми-переменные для каждого возможного значения качественной переменной.}


\end{enumerate}

\section{Деревья и Random Forest}

\begin{enumerate}

\item Для случайных величин  $X$ и $Y$ найдите индекс Джини и энтропию


\begin{tabular}{ccc}
$X$ & $0$ & $1$ \\ 
\hline 
$\P()$ & $0.2$ & $0.8$ \\ 
\end{tabular},
\begin{tabular}{cccc}
$Y$ & $0$ & $1$ & $5$ \\ 
\hline 
$\P()$ & $0.2$ & $0.3$ & $0.5$ \\ 
\end{tabular} 

\solution{}

\item Случайная величина $X$ принимает значение $1$ с вероятностью $p$ и значение $0$ с вероятностью $1-p$.
\begin{enumerate}
\item Постройте график зависимости индекса Джини и энтропии от $p$
\item При каком $p$ энтропия и индекс Джини будут максимальны?
\end{enumerate}
\solution{}


\item табличка с тремя признаками...
\begin{enumerate}
\item Какой фактор нужно использовать при прогнозировании $y$, чтобы минимизировать энтропию?
\item Какой фактор нужно использовать при прогнозировании $y$, чтобы минимизировать индекс Джини?
\end{enumerate}




\end{enumerate}


\section{МЕГАМАТРИЦА (операции со случайными векторами)}

\begin{enumerate}
\item В рамках классической линейной модели найдите все математические ожидания и все ковариационные матрицы всех пар случайных векторов: $\ve$, $y$, $\hy$, $\he$, $\hb$. Т.е. найдите $\E(\e)$, $\E(y)$, \ldots и $\Cov(\e,y)$, $\Cov(\e,\hy)$, \ldots
\solution{$\Var(\hb)=\sigma^2 (X'X)^{-1}$}

\item Найдите $\E(\sum (\e_i-\bar{\e})^2 )$, $\E(RSS)$
\solution{ $(n-1)\sigma^2$, $(n-k)\sigma^2$}

\item Используя матрицы $P=X(X'X)^{-1}X'$ и $\pi=\v1(\v1'\v1)^{-1}\v1'$ запишите $RSS$, $TSS$ и $ESS$ в матричной форме
\solution{$TSS=y'(I-\pi)y$, $RSS=y'(I-P)y$, $ESS=y'(P-\pi)y$ }


\item $\E(TSS)$, $\E(ESS)$ --- громоздкие 
\solution{ $\E(TSS)=(n-1)\sigma^2+\beta'X'(I-\pi)X\beta$}

\item Вася строит регрессию $y$ на некий набор объясняющих переменных и константу. А на самом деле $y_i=\beta_1+\e_i$. Чему равно $\E(TSS)$, $\E(RSS)$, $\E(ESS)$ в этом случае?
\solution{ $(n-1)\sigma^2$, $(n-k)\sigma^2$, $(k-1)\sigma^2$}


\item Известно, что $\e\sim N(0,I)$, $\e=(\e_1,\e_2,\e_3)'$. Матрица $A=\left(\begin{matrix}
2/3 & -1/3 & -1/3 \\ 
-1/3 & 2/3 & -1/3 \\ 
-1/3 & -1/3 & 2/3
\end{matrix}\right)$.
\begin{enumerate}
\item Найдите $\E(\e'A\e)$
\item Как распределена случайная величина $\e' A\e$?
\end{enumerate}
\solution{по $\chi^2$-распределению }

\item Известно, что $\e\sim N(0,A)$, $\e=(\e_1,\e_2)'$. Матрица $A=\left(\begin{matrix}
4 & 1 \\ 
1 & 4 
\end{matrix}\right)$, матрица $B=\left(\begin{matrix}
-1 & 3 \\ 
2 & 1 
\end{matrix}\right)$
\begin{enumerate}
\item Как распределен вектор $h=B\e$?
\item Найдите $A^{-1/2}$
\item Как распределен вектор $u=A^{-1/2}\e$?
\end{enumerate}
\solution{ $u\sim N(0,I)$ }


\item Известна ковариационная матрица вектора $\e=(\e_1,\e_2)$,
\[
\Var(\e)=\left(
\begin{matrix}
9 & -1 \\
-1 & 9
\end{matrix}
\right)
\]

Найдите четыре различных матрицы $A$, таких что вектор $v=A\e$ имеет некоррелированные компоненты с единичной дисперсией, то есть $\Var(A\e)=I$.
\solution{}



\item Случайные величины $w_1$ и $w_2$ независимы и нормально распределены, $N(0,1)$. Из них составлено два вектора, 
$w=\left(
\begin{array}{c}
w_1 \\
w_2
\end{array}\right)$
и 
$z=\left(
\begin{array}{c}
-w_2 \\
w_1
\end{array}\right)$
\begin{enumerate}
\item Являются ли векторы $w$ и $z$ перпендикулярными?
\item Найдите $\E(w)$, $\E(z)$
\item Найдите $\Var(w)$, $\Var(z)$, $\Cov(w,z)$
\item Рассмотрим классическую линейную модель. Являются ли векторы $\he$ и $\hy$ перпендикулярными? Найдите $\Cov(\he,\hy)$.
\end{enumerate}
\solution{}

\item Есть случайный вектор $w=(w_1, w_2, \ldots, w_n)'$. 
\begin{enumerate}
\item Возможно ли, что $E(w)=0$ и $\sum w_i=0$?
\item Возможно ли, что $E(w)\neq 0$ и $\sum w_i=0$?
\item Возможно ли, что $E(w)=0$ и $\sum w_i \neq 0$?
\item Возможно ли, что $E(w)=\neq $ и $\sum w_i \neq 0$?
\item Чему в классической модели регрессии равны: $\E(\e)$ и $\sum \e_i$?
\item Чему в классической модели регрессии равны: $\E(\he)$ и $\sum \he_i$?
\end{enumerate}
\solution{Каждый из вариантов возможен}




\end{enumerate}


\section{Метод максимального правдоподобия}

\begin{enumerate}
\item Выпишите в явном виде функцию максимального правдоподобия для модели $y=\b_1+\b_2 x+\e$, если $\e\sim N(0,A)$. 
Матрица $A$ устроена по принципу: $\Cov(\e_i,\e_j)=0$ при $i\neq j$, и $\Var(\e_i)=\sigma^2 x_i^2$.
\solution{}

\item Выпишите в явном виде функцию максимального правдоподобия для модели $y=\b_1+\b_2 x+\e$, если $\e\sim N(0,A)$. 
Матрица $A$ устроена по принципу: $\Cov(\e_i,\e_j)=0$ при $i\neq j$, и $\Var(\e_i)=\sigma^2 |x_i|$.
\solution{}

\item Винни-Пух знает, что мёд бывает правильный, $honey_i=1$, и неправильный, $honey_i=0$. Пчёлы также бывают правильные, $bee_i=1$, и неправильные, $bee_i=0$. По 100 своим попыткам добыть мёд Винни-Пух составил таблицу сопряженности:


\begin{tabular}{c|cc}
 & $honey_i=1$ & $honey_i=0$ \\ 
\hline 
$bee_i=1$ & 12 & 36 \\ 
$bee_i=0$ & 32 & 20 \\ 
\end{tabular} 

Используя метод максимального правдоподобия Винни-Пух хочет оценить логит-модель для прогнозирования правильности мёда с помощью правильности пчёл:
\[
\ln \left(\frac{\P(honey_i=1)}{\P(honey_i=0)} \right)=\beta_1 + \beta_2 bee_i 
\]
\begin{enumerate}
\item Выпишите функцию правдоподобия для оценки параметров $\beta_1$ и $\beta_2$
\item Оцените неизвестные параметры
\item С помощью теста отношения правдоподобия проверьте гипотезу о том, правильность пчёл не связана с правильностью мёда на уровне значимости 5\%.
\item Держась в небе за воздушный шарик, Винни-Пух неожиданно понял, что перед ним неправильные пчёлы. Помогите ему оценить вероятность того, что они делают неправильный мёд.
\end{enumerate}
\solution{}


\item Пусть $p$ --- неизвестная вероятность выпадения орла при бросании монеты. Из 100 испытаний  42 раза выпал <<Орел>> и 58 --- <<Решка>>. 
\begin{enumerate}
\item Найдите оценку $\hat{p}$ методом максимального правдоподобия
\item Постройте 95\% доверительный интервал для $p$
\item Протестируйте на 5\%-ом уровне значимости гипотезу о том, что монетка --- <<правильная>> с помощью теста Вальда, теста множителей Лагранжа, теста отношения правдоподобия
\end{enumerate}
\solution{}


\item Случайная величина $X$ имеет логистическое распределение, если её функция плотности имеет вид $f(x)=e^{-x}/(1+e^{-x})^2$.
\begin{enumerate}
\item Является ли $f(x)$ чётной?
\item Постройте график $f(x)$
\item Найдите функцию распределения, $F(x)$
\item Найдите $\E(X)$, $\Var(X)$
\item На какое известный закон распределения похож логистический?
\end{enumerate}
\solution{$f(x)$ чётная, $\E(X)=0$, $\Var(X)=\pi^2/3$, логистическое похоже на $N(0,1)$}

\item Логит модель часто формулируют в таком виде:
\[
y_i^*=\beta_1+\beta_2 x_i +\e_i
\]
где $\e_i$ имеет логистическое распределение, и 
\[
y_i=\begin{cases}
1,\: y_i^*\geq 0 \\
0,\: y_i^*<0
\end{cases}
\]
\begin{enumerate}
\item Выразите $\P(y_i=1)$ с помощью логистической функции распределения 
\item Найдите $\ln \left(\frac{\P(y_i=1)}{\P(y_i=0)} \right)$
\end{enumerate}
\solution{$\ln \left(\frac{\P(y_i=1)}{\P(y_i=0)} \right)=\beta_1+\beta_2 x_i$.}

\item \useR Сравните на одном графике
\begin{enumerate}
\item Функции плотности логистической и нормальной $N(0,\pi^2/3)$ случайных величин
\item Функции распределения логистической и нормальной $N(0,\pi^2/3)$ случайных величин
\end{enumerate}


\item Как известно, Фрекен Бок любит пить коньяк по утрам. За прошедшие 4 дня она записала, сколько рюмочек коньяка выпила утром, $x_i$, и видела ли она в этот день привидение, $y_i$, 

\begin{tabular}{c|cccc}
$y_i$ & 1 & 0 & 1 & 0 \\
\hline
$x_i$ & 2 & 1 & 3 & 0 
\end{tabular}  

Зависимость между $y_i$ и $x_i$ описывается логит-моделью, 
\[
\ln 
\left(
  \frac{\P(y_i=1)}{\P(y_i=0)}
\right)
=\beta_1+\beta_2 x_i
\]

\begin{enumerate}
\item Выпишите в явном виде логарифмическую функцию максимального правдоподобия
\item \useR Найдите оценки параметров $\beta_1$ и $\beta_2$
\end{enumerate}

\solution{}

\item Дядя Вова (Владимир Николаевич) и Скрипач (Гедеван) зарабатывают на Плюке чатлы, чтобы купить гравицапу. Число заработанных за $i$-ый день чатлов имеет пуассоновское распределение, заработки за разные дни независимы. За прошедшие 100 дней они заработали 250 чатлов. 
\begin{enumerate}
\item Оцените параметр $\lambda$ пуассоновского распределения методом максимального правдоподобия
\item Сколько дней им нужно давать концерты, чтобы оценка вероятности купить гравицапу составила 0.99? Гравицапа стоит пол кц или 2200 чатлов.
\item Постройте 95\% доверительный интервал для $\lambda$
\item Проверьте гипотезу о том, что средний дневной заработок равен 2 чатла с помощью теста отношения правдоподобия, теста Вальда, теста множителей Лагранжа
\end{enumerate}
\solution{}




\item Инопланетянин Капп совершил вынужденную посадку на Землю. Каждый день он выходит на связь со своей далёкой планетой. Продолжительность каждого сеанса связи имеет экспоненциальное распределение с параметром $\lambda$. Прошедшие 100 сеансов связи в сумме длились 11 часов.
\begin{enumerate}
\item Оцените параметр $\lambda$ экспоненциального распределения методом максимального правдоподобия
\item Постройте 95\% доверительный интервал для $\lambda$
\item Проверьте гипотезу о том, что средняя продолжительность сеанса связи равна 5 минутам с помощью теста отношения правдоподобия, теста Вальда, теста множителей Лагранжа
\end{enumerate}
\solution{}

\item Предположим, что в классической линейной модели ошибки имеют нормальное распределение, т.е.
\[
y_i=\beta_1+\beta_2 x_{2,i}+\ldots+\beta_k x_{k,i}+\e_i
\]
где $\e_i$ нормальны $N(0,\sigma^2)$ и независимы
\begin{enumerate}
\item Найдите оценки для $\beta$ и $\sigma^2$ методом максимального правдоподобия. 
\item Являются ли полученные оценки $\hb_{ML}$ и $\hs^2_{ML}$ несмещенными?
\item Выведите формулу $LR$-статистики у теста отношения правдоподобия для тестирования гипотезы об адекватности регрессии $H_0$: $\beta_2=\beta_3=\ldots=\beta_k=0$.
\end{enumerate}
\solution{}


\item Наблюдения $X_1$, \ldots, $X_n$ независимы и нормальны $N(\mu,1)$. По 100 наблюдениям оказалось, что $\sum x_i=200$, $\sum x_i^2=900$.
\begin{enumerate}
\item Оцените $\mu$ методом максимального правдоподобия
\item Постройте 95\% доверительный интервал для $\mu$
\item Проверьте гипотезу о том, что $\mu=3$ против альтернативной $\mu\neq 3$ с помощью тестов Вальда, множителей Лагранжа и отношения правдоподобия
\item Постройте 95\% доверительный интервал для неизвестной величины $\P(X_i>2.5)$
\end{enumerate}
\solution{}

\item Наблюдения $X_1$, \ldots, $X_n$ независимы и нормальны $N(0,\sigma^2)$. По 100 наблюдениям оказалось, что $\sum x_i=200$, $\sum x_i^2=900$.
\begin{enumerate}
\item Оцените $\sigma^2$ методом максимального правдоподобия
\item Постройте 95\% доверительный интервал для $\sigma^2$
\item Проверьте гипотезу о том, что $\sigma^2=4$ против альтернативной $\sigma^2\neq 4$ с помощью тестов Вальда, множителей Лагранжа и отношения правдоподобия
\item Постройте 95\% доверительный интервал для неизвестной величины $\P(X_i>2.5)$
\end{enumerate}
\solution{}

\item Наблюдения $X_1$, \ldots, $X_n$ независимы и нормальны $N(\mu,\sigma^2)$. По 100 наблюдениям оказалось, что $\sum x_i=200$, $\sum x_i^2=900$.
\begin{enumerate}
\item Оцените $\mu$ и $\sigma^2$ методом максимального правдоподобия
\item Постройте 95\% доверительный интервал для $\mu$, $\sigma^2$
\item \useR Проверьте гипотезу о том, что $\sigma^2=4$ против альтернативной $\sigma^2\neq 4$ с помощью тестов Вальда, множителей Лагранжа и отношения правдоподобия
\item \useR Проверьте гипотезу о том, что $\mu=3$ против альтернативной $\mu\neq 3$ с помощью тестов Вальда, множителей Лагранжа и отношения правдоподобия
\item \useR Постройте 95\% доверительный интервал для неизвестной величины $\P(X_i>2.5)$
\item \useR На графике постройте двумерную 95\% доверительную область для вектора $(\mu,\sigma^2)$
\end{enumerate}
\solution{}

\item \useR По ссылке \url{http://people.reed.edu/~jones/141/Coal.html} скачайте данные о количестве крупных аварий на английских угольных шахтах. 
\begin{enumerate}
\item Методом максимального правдоподобия оцените две модели: 
\begin{enumerate}
\item Пуассоновская модель: количества аварий независимы и имеют Пуассоновское распределение с параметром $\lambda$.
\item Модель с раздутым нулём  <<zero inflated poisson model>>: количества аварий независимы, с вероятностью $p$ аварий не происходит вообще, с вероятностью $(1-p)$ количество аварий имеет Пуассоновское распределение с параметром $\lambda$. Смысл этой модели в том, что по сравнению с Пуассоновским распределением у события $\{X_i=0\}$ вероятность выше, а пропорции вероятностей положительных количеств аварий сохраняются. В модели с раздутым нулём дисперсия и среднее количества аварий отличаются. Чему в модели с раздутым нулём равна $\P(X_i=0)$?
\end{enumerate}
\item С помощью тестов множителей Лагранжа, Вальда и отношения правдоподобия проверьте гипотезу $H_0$: верна пуассоновская модель против $H_{a}$: верна модель с раздутым нулём
\item Постройте доверительные интервалы для оценённых параметров в обоих моделях
\item Постройте доверительный интервал для вероятности полного отсутствия аварий по обеим моделям
\end{enumerate}


\end{enumerate}



\section{Голая линейная алгебра}

Здесь будет собран минимум задач по линейной алгебре.

\begin{enumerate}
\item \problem{Приведите пример таких $A$ и $B$, что $\det(AB)\neq \det(BA)$.}
\solution{Например, $A=(1,2,3)$, $B=(1,0,1)'$}

\item Для матриц-проекторов $\pi=\v1(\v1'\v1)^{-1}\v1'$ и $P=X(X'X)^{-1}X'$ найдите $\tr(\pi)$, $\tr(P)$, $\tr(I-\pi)$, $\tr(I-P)$.
\solution{$\tr(I)=n$, $\tr(\pi)=1$, $\tr(P)=k$ }

\item Выпишите в явном виде матрицы $X'X$, $(X'X)^{-1}$ и $X'y$, если

$y=\left(
\begin{array}{c}
y_1 \\
y_2 \\
\vdots \\
y_n 
\end{array}\right)$ и
$X=\left(
\begin{array}{cc}
1 & x_1 \\
1 & x_2 \\
\vdots & \vdots \\
1 & x_n 
\end{array}\right)$ 
\solution{ }


\item Выпишите в явном виде матрицы $\pi$, $\pi y$, $\pi \e$, $I-\pi$, если $\pi=\v1(\v1'\v1)^{-1}\v1'$.
 
\end{enumerate}


\section{Парадигма случайных величин}

\begin{enumerate}
\item Найдите $E(Y|X)$
\item Про многомерное нормальное распределение

\item Известна совместная функция плотности пары величин $X_i$, $Y_i$
\[
f(x,y)=
\]
Найдитe 
\begin{enumerate}
\item $\E(X_i)$, $\E(Y_i)$, $\Var(X_i)$, $\Var(Y_i)$, $\Cov(X_i,Y_i)$
\item $\E(Y_i \mid X_i)$, $\E(X_i \mid Y_i)$
\item Вася оценивает модель $y_i=\beta_1+\beta_2 x_i+\epsilon_i$ по огромному количеству наблюдений, $n>>0$. Чему примерно у него окажутся равны $\hb_1$, $\hb_2$, $\hs^2$, $\widehat{\Var}(\hb_2)$? Чему равно $\E(\hb_2)$? (или оно не будет браться???)
\item Петя оцениваем модель $y_i=\beta_1+\beta_2 x_i+\beta_2 x_i^2+\epsilon_i$. Найдите $\E(\hb_1)$, $\E(\hb_2)$, $\E(\hb_3)$, $\Var(\hb)$ (?)
\end{enumerate}

\end{enumerate}

\section{Метод Монте-Карло}

сюда же mcmc для линейной регрессии

\begin{enumerate}
\item На парковку ширины $a$ приезжают машины ширины в один условный метр. Парковка не размечена, поэтому машины встают случайно на любое свободное место, куда они могут втиснуться. С помощью симуляций на компьютере определите, сколько в среднем поместится на такой парковке машин в зависимости от $a$.



\end{enumerate}



\section{Программирование}
Все наборы данных доступны по ссылке \url{https://github.com/bdemeshev/em301/wiki/Datasets}.


\begin{enumerate}

\item Задача Иосифа Флавия.

\item Напишите программу, которая печатает сама себя.

\item Задача Макар-Лиманова. У торговца 55 пустых стаканчиков, разложенных в несколько стопок. Пока нет покупателей он развлекается: берет верхний стаканчик из каждой стопки и формирует из них новую стопку. Потом снова берет верхний стаканчик из каждой стопки и формирует из них новую стопку и т.д.
\begin{enumerate}
\item Напишите функцию `makar\_step`. На вход функции подаётся вектор количества стаканчиков в каждой стопке до перекладывания. На выходе функция возвращает количества стаканчиков в каждой стопке после одного перекладывания.
\item Изначально стаканчики были разложены в две стопки, из 25 и 30 стаканчиков. Как разложатся стаканчики если покупателей не будет достаточно долго?
\end{enumerate}
\solution{}





\end{enumerate}




\end{document}